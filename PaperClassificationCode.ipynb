{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J_kuXui40xG"
      },
      "source": [
        "# Necessary Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sINAKeo04qk4",
        "outputId": "450cd393-4d29-439e-9b97-eaa656d76bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.6/514.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q llama-index-llms-huggingface\n",
        "!pip install -q llama-index-llms-huggingface-api\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install -q llama-index-llms-groq\n",
        "!pip install -q unstructured[local-inference]\n",
        "!pip install -q pi_heif\n",
        "%pip install -q llama-index-tools-tavily-research llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k64IWNoyUJ_h",
        "outputId": "b2e1ee3f-511e-4222-884a-bfd754fd8f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (988 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOP0BmT745zW"
      },
      "source": [
        "# Necessary Imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veejzSTd4vao",
        "outputId": "f666d095-b192-455c-fcf7-3deabca4d5a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import VectorStoreIndex, StorageContext, SimpleDirectoryReader, Settings\n",
        "from llama_index.llms.groq import Groq\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "import re\n",
        "from llama_index.core.schema import Document\n",
        "from huggingface_hub import login\n",
        "import re\n",
        "from llama_index.core.schema import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GRTAJsv4-lI"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HZABdEsb4ys3"
      },
      "outputs": [],
      "source": [
        "def perform_the_initializations():\n",
        "  HF_TOKEN=\"hf_abcdefgh\"\n",
        "  login(token=HF_TOKEN)\n",
        "\n",
        "  # GROQ_API_KEY=\"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\"      #This is yash's api key. This is the one currently being used. After you get rate limit exceeded error, use nandu's api key.\n",
        "  GROQ_API_KEY=\"gsk_1234567\"     #This is nandu's api key.\n",
        "  Settings.llm=Groq(model=\"llama3-70b-8192\", api_key=GROQ_API_KEY)  #Changes the default llm used to this model and so doesn't require open_AI API key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WO0c0rzm_Q3H"
      },
      "outputs": [],
      "source": [
        "# def extract_the_sections(read_from_path):\n",
        "#   elements=partition_pdf(filename=read_from_path)\n",
        "#   main_sections={}\n",
        "#   current_main_heading=None\n",
        "\n",
        "#   # main_heading_types={\"Title\", \"UncategorizedText\"}\n",
        "#   main_heading_types={\"Title\"}\n",
        "\n",
        "#   for element in elements:\n",
        "#     if element.category in main_heading_types:\n",
        "#       current_main_heading=element.text.strip()\n",
        "#       main_sections[current_main_heading]=\"\"\n",
        "#     elif current_main_heading:\n",
        "#       main_sections[current_main_heading]+=\"\\n\" + element.text.strip()\n",
        "\n",
        "\n",
        "#   def get_section_by_keyword(sections, keywords):\n",
        "#     for heading, content in sections.items():\n",
        "#       if any(re.search(keyword, heading, re.IGNORECASE) for keyword in keywords):\n",
        "#         return heading, content.strip()\n",
        "#     return None\n",
        "\n",
        "#   # for heading, content in main_sections.items():\n",
        "#   #   print(f\"Heading: {heading}\\nContent: {content}\\n\")\n",
        "\n",
        "#   intro_heading, intro=get_section_by_keyword(main_sections, [\"Introduction\"])\n",
        "#   conclusion_heading, conclusion=get_section_by_keyword(main_sections, [\"Conclusion\"])\n",
        "#   abstract_heading, abstract=get_section_by_keyword(main_sections, [\"Abstract\"])\n",
        "\n",
        "#   sections_to_remove={intro_heading, conclusion_heading, abstract_heading}\n",
        "#   remaining_sections={\n",
        "#       heading: content for heading, content in main_sections.items() if heading not in sections_to_remove\n",
        "#   }\n",
        "\n",
        "#   remaining_text=\"\\n\".join(content.strip() for content in remaining_sections.values())\n",
        "#   # print(\"Remaining Content:\")\n",
        "#   # print(remaining_text)\n",
        "#   return [intro_heading, intro, conclusion_heading, conclusion, abstract_heading, abstract, remaining_text]\n",
        "\n",
        "def extract_the_sections(read_from_path):\n",
        "  elements=partition_pdf(filename=read_from_path)\n",
        "  main_sections={}\n",
        "  current_main_heading=None\n",
        "\n",
        "  # main_heading_types={\"Title\", \"UncategorizedText\"}\n",
        "  main_heading_types={\"Title\"}\n",
        "\n",
        "  for element in elements:\n",
        "    if element.category in main_heading_types:\n",
        "      current_main_heading=element.text.strip()\n",
        "      main_sections[current_main_heading]=\"\"\n",
        "    elif current_main_heading:\n",
        "      main_sections[current_main_heading]+=\"\\n\" + element.text.strip()\n",
        "\n",
        "\n",
        "  def get_section_by_keyword(sections, keywords):\n",
        "    for heading, content in sections.items():\n",
        "      if any(re.search(keyword, heading, re.IGNORECASE) for keyword in keywords):\n",
        "        return heading, content.strip()\n",
        "    return None\n",
        "\n",
        "  list_of_headings = []\n",
        "  for heading, content in main_sections.items():\n",
        "    list_of_headings.append(heading)\n",
        "\n",
        "  sections_to_remove = []\n",
        "  list_of_headings1 = \",\".join(list_of_headings)\n",
        "  # print(list_of_headings)\n",
        "  perform_the_initializations()\n",
        "  embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "  heading_index=VectorStoreIndex.from_documents([Document(text=list_of_headings1)], embed_model=embed_model)\n",
        "  query_engine=heading_index.as_query_engine()\n",
        "  extraction_prompt = prompt = \"\"\"\n",
        "You are an expert in text analysis and summarization. You will be provided with a list of document headings as a string. Your task is to analyze the headings and extract only those that correspond to general sections like \"Introduction,\" \"Abstract,\" \"Conclusion,\" or similar, which are typically found in research papers or reports. Additionally, account for variations or synonyms of these headings, such as \"Overview\" (similar to Introduction) or \"Summary\" (similar to Conclusion).\n",
        "\n",
        "### Instructions:\n",
        "1. Carefully analyze the list of headings provided.\n",
        "2. Select headings that are related to general sections, even if they are phrased differently. Some examples include:\n",
        "   - Abstract: Could also be phrased as \"Executive Summary,\" \"Summary,\" or \"Overview.\"\n",
        "   - Introduction: Could also be phrased as \"Preface\" or \"Opening.\"\n",
        "   - Conclusion: Could also be phrased as \"Closing Remarks,\" \"Final Thoughts,\" or \"Summary of Findings.\"\n",
        "   - Related Work: Could also be phrased as \"Literature Review\" or \"Prior Work.\"\n",
        "   - Discussion: Could also be phrased as \"Insights\" or \"Interpretation.\"\n",
        "3. Avoid selecting headings that are specific to detailed sections, such as:\n",
        "   - Methodology: Includes headings like \"Approach,\" \"Procedure,\" or \"Implementation Details.\"\n",
        "   - Results: Includes headings like \"Findings,\" \"Experimental Results,\" or \"Data Analysis.\"\n",
        "   - Analysis: Includes headings like \"Evaluation,\" \"Performance Metrics,\" or \"Case Study.\"\n",
        "\n",
        "### Output:\n",
        "- Return the filtered headings as a single string, separated by commas.\n",
        "- Ensure the output includes only the relevant headings based on the expanded criteria above.\n",
        "\n",
        "Example Input:\n",
        "\"Executive Summary, Preface, Methodology, Experimental Results, Discussion, Final Thoughts, Approach\"\n",
        "\n",
        "Example Output:\n",
        "\"Executive Summary, Preface, Discussion, Final Thoughts\" Response should only be this line\n",
        "\"\"\"\n",
        "\n",
        "  response=query_engine.query(\n",
        "      extraction_prompt\n",
        "  )\n",
        "  list_of_headings_to_remove = response.response.split(',')\n",
        "\n",
        "  # intro_heading, intro=get_section_by_keyword(main_sections, [\"Introduction\"])\n",
        "\n",
        "\n",
        "  section_to_remove = []\n",
        "  for item in list_of_headings_to_remove:\n",
        "    item_heading, content = get_section_by_keyword(main_sections, [str(item.strip())])\n",
        "    section_to_remove.append(item_heading)\n",
        "  remaining_sections={\n",
        "      heading: content for heading, content in main_sections.items() if heading not in sections_to_remove\n",
        "  }\n",
        "  remaining_text=\"\\n\".join(content.strip() for content in remaining_sections.values())\n",
        "\n",
        "  return remaining_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5LH025STmvu"
      },
      "outputs": [],
      "source": [
        "# from llama_index.retrievers import VectorIndexRetriever\n",
        "# from llama_index.query_engine import RetrieveQueryEngine\n",
        "# from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "# retriever=VectorIndexRetriever(index=index, similarity_top_k=2)\n",
        "# postprocessor=SimilarityPostprocessor(similarity_cutoff=0.80)\n",
        "# query_engine=RetrieveQueryEngine(retriever=retriever, node_postprocessor=[postprocessor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h218bFS5_4Jf"
      },
      "source": [
        "### Task1 Helper Functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mwhmhtrE_Xi0"
      },
      "outputs": [],
      "source": [
        "def Extract_relevant_text(file_path):\n",
        "  #Have to write a new function that will obtain the relevant text to methodology and then return that while also dealing with the inconsistency of titles across the different research papers.\n",
        "  # intro_heading, intro, conclusion_heading, conclusion, abstract_heading, abstract, remaining_text=extract_the_sections(file_path)\n",
        "  remaining_text=extract_the_sections(file_path)\n",
        "  return remaining_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByBe6f3I_9im"
      },
      "source": [
        "### Task2 Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j5y7K5Gq_-3J"
      },
      "outputs": [],
      "source": [
        "def entire_pdf_to_text(file_path):\n",
        "  elements = partition_pdf(filename=file_path)\n",
        "  text = \"\\n\".join([element.text for element in elements if element.text])\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1QmYedH11ww"
      },
      "outputs": [],
      "source": [
        "# # Set up Tavily tool\n",
        "from llama_index.tools.tavily_research.base import TavilyToolSpec\n",
        "\n",
        "# tavily_tool = TavilyToolSpec(\n",
        "#     api_key=\"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\",\n",
        "# )\n",
        "\n",
        "# tavily_tool_list = tavily_tool.to_tool_list()\n",
        "\n",
        "# # results = tavily_tool.search(\"What happened in the latest Burning Man festival?\", max_results=3)\n",
        "# # for item in results:\n",
        "# #   print(\"Printing/n\", item.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKRGO-vaIfK-"
      },
      "outputs": [],
      "source": [
        "# def Perform_Task1_with_chain_of_thought(file_path):\n",
        "#     from langchain.embeddings import HuggingFaceEmbedding\n",
        "#     from langchain.vectorstores import VectorStoreIndex\n",
        "#     from langchain.schema import Document\n",
        "\n",
        "#     embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "#     # Extract relevant text from the PDF file (assuming you have this function implemented)\n",
        "#     methodology_relevant_text = Extract_relevant_text(file_path)\n",
        "\n",
        "#     # Create a vector store index from the extracted methodology text\n",
        "#     methodology_index = VectorStoreIndex.from_documents([\n",
        "#         Document(text=methodology_relevant_text)\n",
        "#     ], embed_model=embed_model)\n",
        "\n",
        "#     # Create the initial query engine\n",
        "#     query_engine = methodology_index.as_query_engine()\n",
        "\n",
        "#     # Base prompt with explicit step-by-step reasoning requirement\n",
        "#     base_prompt = '''\n",
        "#     You are an expert research assistant. You will be provided with a PDF research paper (attached). Your task is to carefully read and analyze the paper to assess the accuracy and validity of its findings based on its methodology and evidence.\n",
        "\n",
        "#     Key Objectives:\n",
        "#     1. Understand and Evaluate: Carefully review the attached PDF to understand the paper's research design, methodology, findings, and conclusions.\n",
        "#     2. Assess Accuracy: Verify whether the findings and conclusions presented in the paper are supported by the provided data, methods, and logical reasoning.\n",
        "#     3. Logic Check: Identify any inconsistencies, logical errors, or gaps in the research methodology or analysis that undermine the validity of the findings.\n",
        "\n",
        "#     Instructions:\n",
        "#     1. Read and Understand the Paper: Review the attached PDF to grasp its context, methodology, findings, and conclusions.\n",
        "#     2. Generate Intermediate Steps: Provide only one logical step or piece of analysis at a time. Do not attempt to generate the entire assessment in one step.\n",
        "#     3. Check Consistency and Logic: Evaluate the paper's methods and results step by step. At each step, identify what is clear, what remains uncertain, and what additional information is needed to proceed further.\n",
        "#     4. Assess for Publication:\n",
        "#       - Do not conclude \"Publishable\" or \"Non-Publishable\" until all logical steps have been explicitly addressed.\n",
        "#       - If the findings and conclusions are fully supported and accurate based on the provided evidence and logic, output: only the word \"Publishable\".\n",
        "#       - If there are significant inaccuracies, logical gaps, or unsupported conclusions, output: only the word \"Non-Publishable\".\n",
        "\n",
        "#     Important Note: Base your assessment only on the content of the paper. Avoid personal interpretations, speculations, or filling gaps with external information. Provide step-by-step reasoning in your intermediate responses.\n",
        "#     '''\n",
        "\n",
        "#     # Initialize chain-of-thought prompt\n",
        "#     chain_of_thought_prompt = base_prompt\n",
        "\n",
        "#     # Loop for iterative chain-of-thought questioning\n",
        "#     while True:\n",
        "#         # Query the current chain-of-thought prompt\n",
        "#         response = query_engine.query(chain_of_thought_prompt)\n",
        "\n",
        "#         # Check if the response indicates further reasoning is needed\n",
        "#         if \"Publishable\" in response or \"Non-Publishable\" in response:\n",
        "#             # Ensure it has reached the conclusion after step-by-step reasoning\n",
        "#             if \"Generate Intermediate Steps\" in chain_of_thought_prompt:\n",
        "#                 return response  # Return the final decision\n",
        "\n",
        "#         # If no final decision, add intermediate response to prompt and continue\n",
        "#         intermediate_question = \"What additional specific inconsistencies, logical gaps, or unsupported conclusions can you identify?\"\n",
        "#         chain_of_thought_prompt += f\"\\nIntermediate Question: {intermediate_question}\\nResponse: {response}\\n\"\n",
        "#         chain_of_thought_prompt += intermediate_question\n",
        "\n",
        "# # Example Usage\n",
        "# # result = Perform_Task1_with_chain_of_thought(\"path/to/research_paper.pdf\")\n",
        "# # print(result)\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def Perform_Task1_with_chain_of_thought(file_path):\n",
        "    # from langchain.embeddings import HuggingFaceEmbedding\n",
        "    # from langchain.vectorstores import VectorStoreIndex\n",
        "    # from langchain.schema import Document\n",
        "\n",
        "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "    # Extract relevant text from the PDF file (assuming you have this function implemented)\n",
        "    methodology_relevant_text = Extract_relevant_text(file_path)\n",
        "\n",
        "    # Create a vector store index from the extracted methodology text\n",
        "    methodology_index = VectorStoreIndex.from_documents([\n",
        "        Document(text=methodology_relevant_text)\n",
        "    ], embed_model=embed_model)\n",
        "\n",
        "    # Create the initial query engine\n",
        "    query_engine = methodology_index.as_query_engine()\n",
        "\n",
        "    # Base prompt with explicit step-by-step reasoning requirement\n",
        "    base_prompt = '''\n",
        "    You are an expert research assistant. You will be provided with a PDF research paper (attached). Your task is to carefully read and analyze the paper to assess the accuracy and validity of its findings based on its methodology and evidence.\n",
        "\n",
        "    Key Objectives:\n",
        "    1. Understand and Evaluate: Carefully review the attached PDF to understand the paper's research design, methodology, findings, and conclusions.\n",
        "    2. Assess Accuracy: Verify whether the findings and conclusions presented in the paper are supported by the provided data, methods, and logical reasoning.\n",
        "    3. Logic Check: Identify any inconsistencies, logical errors, or gaps in the research methodology or analysis that undermine the validity of the findings.\n",
        "\n",
        "    Instructions:\n",
        "    1. Read and Understand the Paper: Review the attached PDF to grasp its context, methodology, findings, and conclusions.\n",
        "    2. Generate Intermediate Steps: Provide only one logical step or piece of analysis at a time. Do not attempt to generate the entire assessment in one step.\n",
        "    3. Check Consistency and Logic: Evaluate the paper's methods and results step by step. At each step, identify what is clear, what remains uncertain, and what additional information is needed to proceed further.\n",
        "    4. Assess for Publication:\n",
        "      - Do not conclude \"Publishable\" or \"Non-Publishable\" until all logical steps have been explicitly addressed.\n",
        "      - If the findings and conclusions are fully supported and accurate based on the provided evidence and logic, output: only the word \"Publishable\".\n",
        "      - If there are significant inaccuracies, logical gaps, or unsupported conclusions, output: only the word \"Non-Publishable\".\n",
        "    5. If you find some inaccuracies, logical gaps, or unsupported conclusions in some intermediate logic, output: '\"Inconsistency Identified\": Mention the part in the paper where there is an inaccuracy'\n",
        "\n",
        "    Important Note: Base your assessment only on the content of the paper. Avoid personal interpretations, speculations, or filling gaps with external information. Provide step-by-step reasoning in your intermediate responses.\n",
        "    Important Note: Mention the accuracy identiy in this format so that I can access it later {\"Inconsistency Identified\": Ask the question whose answer you want to find out} in such a dictionary format only\n",
        "    Important Note: While reviewing the paper, it is not necessary to focus excessively on minor inconsistencies, especially if the paper mentions the use of external references (e.g., internet sources) for certain claims. It is acceptable to overlook minor issues, as overly scrutinizing every detail could result in marking almost every paper as \"Unpublishable.\"\n",
        "\n",
        "    The purpose of the intermediate questions is to only verify if the paper follows the essential steps required to determine whether it is publishable. The goal is not to check every step in extreme detail but to ensure that the paper’s methodology and conclusions are fundamentally sound and meet the standards for publication.\n",
        "'''\n",
        "\n",
        "    # Initialize chain-of-thought prompt\n",
        "    chain_of_thought_prompt = base_prompt\n",
        "\n",
        "    # Limit the number of iterations to prevent infinite loops\n",
        "    max_iterations = 5\n",
        "    iteration_count = 0\n",
        "    print(\"About to enter the while loop.\")\n",
        "    # Loop for iterative chain-of-thought questioning\n",
        "    while iteration_count < max_iterations:\n",
        "      iteration_count += 1\n",
        "      print(\"The iteration count is \", iteration_count)\n",
        "\n",
        "      # Query the current chain-of-thought prompt\n",
        "      response = query_engine.query(chain_of_thought_prompt)\n",
        "      print(\"The response obtained now is \", response)\n",
        "\n",
        "      # print(\"The intermediate response i got inside the iteration \", response)\n",
        "      # print(\"The above thing's type is \", type(response))\n",
        "      # print(\"Doing the .response is giving\", response.response)\n",
        "      # print(\"The above thing's type is \", type(response.response))\n",
        "      # Check if the response concludes the assessment\n",
        "      if \"Publishable\" in response.response or \"Non-Publishable\" in response.response:\n",
        "        print(\"About to return from the publishable, non-publishable if statement with the response: \", response.response)\n",
        "        return response.response\n",
        "\n",
        "      text = response.response\n",
        "      match = re.search(r\"\\{(.*?)\\}\", text)\n",
        "      flag = False\n",
        "      if match:\n",
        "        content_inside_braces = match.group(1)\n",
        "        flag = True\n",
        "        print(\"Extracted content:\", content_inside_braces)\n",
        "      else:\n",
        "        print(\"No content found inside braces.\")\n",
        "\n",
        "      additional_text = \"\"\n",
        "\n",
        "      if flag == True:\n",
        "        tavily_tool = TavilyToolSpec(api_key=\"tvly-876489764987\",)\n",
        "        tavily_tool_list = tavily_tool.to_tool_list()\n",
        "        results = tavily_tool.search(content_inside_braces.split(\":\")[1], max_results=1)\n",
        "\n",
        "        for item in results:\n",
        "          additional_text += item.text\n",
        "\n",
        "        print(f\"Additiconal text Extracted is :{additional_text} for topic {content_inside_braces.split(':')[1]}\")\n",
        "      # If no final decision, add intermediate response to prompt and continue\n",
        "      # print(f\"Additiconal text Extracted is :{additional_text} for topic {content_inside_braces.split(':')[1]}\")\n",
        "\n",
        "      chain_of_thought_prompt += f\"\\nResponse: {response}\\n\"\n",
        "      chain_of_thought_prompt += f\"\\Additional data from websearch: {additional_text}\\n\"\n",
        "      intermediate_question = \"Does the additional content added give answer to your previous inconsistency. If it doesn't adderes keep that in mind and move on to the next part.\"\n",
        "      chain_of_thought_prompt += f\"Intermediate Question: {intermediate_question}\\n\"\n",
        "\n",
        "      print(\"Finished updating the chain_of_thought_prompt\")\n",
        "\n",
        "      # If on the last iteration, force a conclusion\n",
        "      if iteration_count == max_iterations:\n",
        "        chain_of_thought_prompt += \"\\nThis is the final iteration. Provide a conclusive assessment: 'Publishable' or 'Non-Publishable'.\"\n",
        "        response = query_engine.query(chain_of_thought_prompt)\n",
        "        print(\"Reached the final iteration with the response being: \", response.response)\n",
        "        return response.response\n",
        "\n",
        "    # If the maximum iterations are reached without a conclusion, return an appropriate message\n",
        "    return \"Unable to determine publishability within the iteration limit.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZk-pJOAABJX"
      },
      "source": [
        "## The main Task functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DVwsx-HdAD3f"
      },
      "outputs": [],
      "source": [
        "# def Perform_Task1(file_path):\n",
        "#   # task1_COT= Perform_Task1_with_chain_of_thought(file_path)\n",
        "#   # if \"Non-Publishable\" in task1_COT:\n",
        "#   #   return \"Non-Publishable\"\n",
        "#   # else:\n",
        "#   #   return \"Publishable\"\n",
        "#   embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "#   methodology_relevant_text=Extract_relevant_text(file_path)\n",
        "#   methodology_index=VectorStoreIndex.from_documents([Document(text=methodology_relevant_text)], embed_model=embed_model)\n",
        "#   publishability_query_engine=methodology_index.as_query_engine()\n",
        "#   publishability_classification_prompt=f'''\n",
        "#   You are an expert research assistant. You will be provided with a PDF research paper (attached). Your task is to carefully read and analyze the paper to assess the accuracy and validity of its findings based on its methodology and evidence.\n",
        "\n",
        "#   Key Objectives:\n",
        "#   1. Understand and Evaluate: Carefully review the attached PDF to understand the paper's research design, methodology, findings, and conclusions.\n",
        "#   2. Assess Accuracy: Verify whether the findings and conclusions presented in the paper are supported by the provided data, methods, and logical reasoning.\n",
        "#   3. Logic Check: Identify any inconsistencies, logical errors, or gaps in the research methodology or analysis that undermine the validity of the findings.\n",
        "\n",
        "\n",
        "#   Instructions:\n",
        "#   1. Read and Understand the Paper: Review the attached PDF to grasp its context, methodology, findings, and conclusions.\n",
        "#   2. Check Consistency and Logic: Evaluate the paper's methods and results step by step, comparing its evidence and data to the stated findings and conclusions. Focus on whether the methodology correctly supports the stated results.\n",
        "#   3. Assess for Publication:\n",
        "#     - If the findings and conclusions are fully supported and accurate based on the provided evidence and logic, output: only the word \"Publishable\".\n",
        "#     - If there are significant inaccuracies, logical gaps, or unsupported conclusions, output: only the word \"Non-Publishable\".\n",
        "\n",
        "\n",
        "#   Important Note: Base your assessment only on the content of the paper. Avoid personal interpretations, speculations, or filling gaps with external information.\n",
        "#   '''\n",
        "\n",
        "#   publishability_response=publishability_query_engine.query(publishability_classification_prompt)\n",
        "#   return publishability_response\n",
        "\n",
        "import re\n",
        "\n",
        "def Perform_Task1_with_lenient_scoring(file_path):\n",
        "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "    methodology_relevant_text = Extract_relevant_text(file_path)\n",
        "\n",
        "    # Create an index with the relevant text\n",
        "    methodology_index = VectorStoreIndex.from_documents([Document(text=methodology_relevant_text)], embed_model=embed_model)\n",
        "    publishability_query_engine = methodology_index.as_query_engine()\n",
        "\n",
        "    # Scoring Prompt\n",
        "    scoring_prompt = f'''\n",
        "    You are an expert research assistant tasked with evaluating a research paper's methodology. Your evaluation should focus solely on the logical flow, consistency, and clarity of the methodology section.\n",
        "\n",
        "    Ignore:\n",
        "    - Discrepancies in parameters or results.\n",
        "    - External validity or replication potential.\n",
        "\n",
        "    Based on the content of the methodology section:\n",
        "    1. Assign a score between 0 and 1 indicating the methodology's publishability. Use the following guidelines:\n",
        "      - 0: The methodology is incoherent, disconnected, or fundamentally flawed.\n",
        "      - 0.5: The methodology is moderately coherent but has notable gaps or unclear steps.\n",
        "      - 1: The methodology is logically consistent, well-connected, and fully understandable.\n",
        "    2. Provide a brief explanation of the score.\n",
        "\n",
        "    **Response Format**:\n",
        "    1. Score: '<score>'\n",
        "    2. Explanation: <The actual explanation>\n",
        "    '''\n",
        "\n",
        "    # Query the model for the lenient scoring\n",
        "    response = publishability_query_engine.query(scoring_prompt)\n",
        "\n",
        "    response_text=response.response\n",
        "    score_pattern = r\"1\\. Score: '([0-1]\\.\\d+|0|1)'\"\n",
        "    explanation_pattern = r\"2\\. Explanation: (.+)\"\n",
        "\n",
        "    score_match = re.search(score_pattern, response_text)\n",
        "    score = float(score_match.group(1)) if score_match else None\n",
        "\n",
        "    explanation_match = re.search(explanation_pattern, response_text, re.DOTALL)\n",
        "    explanation = explanation_match.group(1).strip() if explanation_match else None\n",
        "\n",
        "    return score, explanation\n",
        "\n",
        "    # print(\"Scoring Response:\\n\", response)\n",
        "\n",
        "    # # Extract score from the response (assuming the score is mentioned explicitly)\n",
        "    # try:\n",
        "    #     score = float(response.response.split()[0])  # Simplistic parsing for score extraction\n",
        "    # except (ValueError, IndexError):\n",
        "    #     score = 0  # Default to 0 if parsing fails\n",
        "\n",
        "    # return score, response.response\n",
        "\n",
        "def Perform_Task2(file_path):\n",
        "  embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "  file_text=entire_pdf_to_text(file_path)\n",
        "  conference_index=VectorStoreIndex.from_documents([Document(text=file_text)], embed_model=embed_model)\n",
        "  conference_query_engine=conference_index.as_query_engine()\n",
        "  conference_classification_prompt = f'''\n",
        "  You are an expert in academic research with extensive knowledge of top-tier conferences. You will be provided with a PDF research paper (attached). Your task is to carefully read and analyze the paper to classify it into one of the following conferences based on its topic, methodology, and relevance to the conference themes:\n",
        "\n",
        "  Important Note: The below order of the conferences along with their details is not given any priority order. Only analyse the paper to check with which conference, the methodology and idea of the paper matches well.\n",
        "\n",
        "  1. **CVPR (Conference on Computer Vision and Pattern Recognition)**:\n",
        "    CVPR is a premier conference in computer vision and pattern recognition. Accepted papers typically address advancements in areas such as image and video processing, object detection, 3D vision, generative models, visual understanding, and multimodal learning. Papers are expected to demonstrate rigorous experimentation, novel methodologies, and practical applications. The conference values contributions with groundbreaking algorithms, real-world relevance, and scalability. Explain how the paper introduces significant improvements or insights in computer vision techniques and benchmarks.\n",
        "\n",
        "  2. **NeurIPS (Neural Information Processing Systems)**:\n",
        "    NeurIPS is a leading venue for machine learning, deep learning, and artificial intelligence research. Papers should contribute novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence. Topics include optimization, reinforcement learning, generative AI, interpretability, and interdisciplinary applications in neuroscience, healthcare, or robotics. High-quality submissions focus on innovation, reproducibility, and societal impact. Explain how the paper advances the state-of-the-art in machine learning or AI, emphasizing both theoretical and practical significance.\n",
        "\n",
        "  3. **EMNLP (Empirical Methods in Natural Language Processing)**:\n",
        "    EMNLP is a top-tier conference for natural language processing research, focusing on empirical methods. Papers should present advancements in text generation, understanding, sentiment analysis, or multilingual NLP, supported by thorough experiments. The conference values innovative approaches that address challenges like low-resource languages, large-scale data processing, or interpretability. Explain how the paper contributes to the NLP field with robust experimental design, innovative architectures, or real-world language applications.\n",
        "\n",
        "  4. **TMLR (Transactions on Machine Learning Research)**:\n",
        "    TMLR accepts high-quality machine learning research that balances theoretical depth and practical relevance. Topics include statistical learning, optimization, model interpretability, fairness, and causal inference. Submissions must include well-reasoned analyses, reproducibility, and substantial contributions to the ML community. Explain how the paper bridges theoretical advancements and practical implications, providing valuable insights into machine learning problems or methodologies.\n",
        "\n",
        "  5. **KDD (Knowledge Discovery and Data Mining)**:\n",
        "    KDD is a premier venue for research in data mining, big data analytics, and knowledge discovery. Accepted papers often introduce scalable algorithms, applications in diverse domains, or frameworks for real-world challenges. Topics include graph mining, anomaly detection, predictive modeling, and ethical considerations in data mining. Highlight how the paper proposes innovative data-driven solutions, scalable techniques, or interdisciplinary applications that align with KDD’s focus on actionable knowledge discovery.\n",
        "\n",
        "  ### Key Objectives:\n",
        "  1. Analyze Content: Read the attached PDF to understand its context, research domain, methodology, and application area.\n",
        "  2. Match Conference Scope: Compare the content of the paper with the scope and focus of the six conferences.\n",
        "  3. Classify the Paper:\n",
        "    - Evaluate the content of the paper and map it to the most relevant conference by matching its primary themes and scope.\n",
        "    - Provide a classification with a brief explanation.\n",
        "\n",
        "  ### Classification Criteria:\n",
        "  - **Focus Area**: What primary domain (e.g., computer vision, machine learning, natural language processing, etc.) does the paper address?\n",
        "  - **Methodology**: Does the paper propose novel algorithms, theoretical frameworks, or practical tools?\n",
        "  - **Application**: Are there specific applications or datasets that fit the scope of the conference?\n",
        "  - **Significance**: How does the paper contribute to the advancement of its field in line with the academic standards of the conference?\n",
        "\n",
        "  ### Output:\n",
        "  - **Primary Domain**: State the primary domain of the paper (e.g., computer vision, natural language processing, etc.).\n",
        "  - **Conference Classification**: If the paper aligns with one of the conferences, mention the name of the conference (e.g., \"CVPR\").\n",
        "  - **Explanation**: Provide a 2-3 sentence explanation of why the paper fits the scope of the specified conference.\n",
        "  - **Classify to One**: Classify the Paper to One of the given Conferences only.\n",
        "'''\n",
        "\n",
        "  conference_response=conference_query_engine.query(conference_classification_prompt)\n",
        "  return conference_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRz0fVLC47NX",
        "outputId": "5e29a5ea-b24e-482d-d5d2-356b0755e3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4I58GQAFNd"
      },
      "source": [
        "# Main Flow of the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yBOUniAGAIRY"
      },
      "outputs": [],
      "source": [
        "def Perform_Tasks(file_path):\n",
        "  perform_the_initializations()\n",
        "\n",
        "  print(\"Inside Perform_Tasks rn, about to perform task1\")\n",
        "  score, task1_ans=Perform_Task1_with_lenient_scoring(file_path)\n",
        "  print(\"Task1 has finished\")\n",
        "  print(\"The task1_ans i got is\", task1_ans)\n",
        "  print(\"The score that i finally got is\", score)\n",
        "  # print(f\"Task1 completed. The file_path: {file_path} is {task1_ans}\")\n",
        "  # print(\"The score of the task1 came out to be \", score)\n",
        "  # print(\"The final response of task1 came out to be \", task1_ans)\n",
        "  # print(\"The type of score is\", type(score))\n",
        "  # task1_ans=task1_ans\n",
        "  task1_res=0\n",
        "  # if task1_ans==\"Non-Publishable\":\n",
        "  if score>0.6:\n",
        "    print(\"Inside the if case of the score being greater than threshold.\")\n",
        "    task1_res=1\n",
        "\n",
        "  print(f\"Publishability?{task1_res}, about to perform task2 if necessary.\")\n",
        "  task2_res=\"na\"\n",
        "  if(task1_res==1):\n",
        "    print(f\"Performing task2 now.\")\n",
        "    task2_ans=Perform_Task2(file_path)\n",
        "    task2_ans=task2_ans.response\n",
        "    print(f\"Returning the following value after finishing task2 {task2_ans}\")\n",
        "    task2_res=task2_ans\n",
        "\n",
        "  return [task1_res, task2_res]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cXCI_pUAKvo",
        "outputId": "f973e40f-87b5-41fc-fcbb-c762a3cedbe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path=\"/content/drive/MyDrive/KDSH_2025_Dataset/Papers\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vriz5E6JAQLZ",
        "outputId": "f2c7c12a-7d72-4099-9e26-1a25bf0800e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The file path is /content/drive/MyDrive/KDSH_2025_Dataset/Papers/P089.pdf\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and logically consistent, with clear explanations of the research question, model definitions, and theorem statements. The authors provide a clear framework for their research, starting with the introduction of the NTK approximation and its importance, followed by the refinement of the bound for extended time scales. The section is well-connected, with each part building upon the previous one. However, there are some gaps in the explanation of the model's rescaling and the lazy training regime, which could be clarified with more detail or examples. Overall, the methodology is clear and understandable, but could benefit from some additional elaboration in certain areas.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Machine Learning\n",
            "\n",
            "**Conference Classification:** NeurIPS\n",
            "\n",
            "**Explanation:** The paper investigates the conditions under which the neural tangent kernel (NTK) approximation remains valid when employing the square loss function for model training. It refines the earlier result from Chizat et al. and establishes the preciseness of the established bound. The paper's focus on the theoretical understanding of neural networks, the NTK approximation, and the lazy training framework aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research.\n",
            "the pdf filename is /content/drive/MyDrive/KDSH_2025_Dataset/Papers/P089.pdf\n",
            "Task2_res **Primary Domain:** Machine Learning\n",
            "\n",
            "**Conference Classification:** NeurIPS\n",
            "\n",
            "**Explanation:** The paper investigates the conditions under which the neural tangent kernel (NTK) approximation remains valid when employing the square loss function for model training. It refines the earlier result from Chizat et al. and establishes the preciseness of the established bound. The paper's focus on the theoretical understanding of neural networks, the NTK approximation, and the lazy training framework aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research.\n",
            "<class 'str'>\n",
            "The values being written are: P089 1 ** NeurIPS ** The paper investigates the conditions under which the neural tangent kernel (NTK) approximation remains valid when employing the square loss function for model training. It refines the earlier result from Chizat et al. and establishes the preciseness of the established bound. The paper's focus on the theoretical understanding of neural networks, the NTK approximation, and the lazy training framework aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research.\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "csv_file_path = 'results.csv'\n",
        "headers = [\"Paper ID\", \"Publishable\", \"Conference\", \"Rationale\"]\n",
        "\n",
        "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(headers)\n",
        "\n",
        "  # for filename in os.listdir(folder_path):\n",
        "  folder_path=\"/content/drive/MyDrive/KDSH_2025_Dataset/Papers/\"\n",
        "  # folder_path=\"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/\"\n",
        "  for i in range(89,90):\n",
        "    # print(filename)\n",
        "    # test_file_path=\"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R001.pdf\"\n",
        "\n",
        "    # file_path=os.path.join(folder_path, f\"P{str(i).zfill(3)}.pdf\")\n",
        "    file_path=os.path.join(folder_path, f\"P{str(i).zfill(3)}.pdf\")\n",
        "    # print(file_path, \"NANDU JHAATU\")\n",
        "    # file_path=test_file_path\n",
        "    print(\"The file path is\", file_path)\n",
        "    task1_res, task2_res=Perform_Tasks(file_path)\n",
        "    # print(\"The task2_res was\", task2_res)\n",
        "    # print(\"The type of task2 res\", type(task2_res))\n",
        "    # print(dir(task2_res))\n",
        "    print('the pdf filename is', file_path)\n",
        "    print(\"Task2_res\", task2_res)\n",
        "    conference_classification=\"na\"\n",
        "    reasoning=\"na\"\n",
        "    if(task2_res!=\"na\"):\n",
        "      response_text = task2_res\n",
        "      # print('response text', response_text)\n",
        "      lines = response_text.splitlines()\n",
        "      conference_classification = lines[2].split(\":\")[1].strip()\n",
        "      print(type(conference_classification))\n",
        "\n",
        "      # Extract the Explanation\n",
        "      reasoning = lines[4].split(\":\")[1].strip()\n",
        "\n",
        "    # reasoning=task2_res\n",
        "    filename=f\"P{str(i).zfill(3)}\"\n",
        "    print(\"The values being written are:\", filename, task1_res, conference_classification, reasoning)\n",
        "    # print(\"The filename being written is\", filename)\n",
        "    print(type(conference_classification))\n",
        "    # print(type(conference_classification.lower()))\n",
        "    writer.writerow([filename, task1_res, conference_classification, reasoning])\n",
        "    # break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmPZM6sm03l"
      },
      "source": [
        "## For testing the accuracy of the prompt, we generate the result.csv file for the reference papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NkCcN1Fm7hw",
        "outputId": "29ee29b5-5e06-4041-ae4a-42fa3cdb3508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section appears to be a collection of unrelated and incoherent statements, with no logical flow or connection between the different experiments and analyses described. The use of novel and unconventional techniques, such as the use of pinball machines and tarot cards, raises concerns about the validity and reliability of the methodology. Additionally, the inclusion of seemingly unrelated topics, such as the history of professional wrestling and the art of sand sculpture, further undermines the coherence of the methodology section. Overall, the methodology section lacks clarity, consistency, and logical flow, making it difficult to understand and evaluate.\n",
            "The score that i finally got is 0.0\n",
            "Publishability?0, about to perform task2 if necessary.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R001.pdf 0 na na\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section appears to be a collection of unrelated and absurd statements, lacking any logical flow or consistency. The text jumps between different topics, including the study of photosynthesis, intergalactic travel, and the art of playing the piano, without providing any clear connection or explanation. The use of fantastical and nonsensical concepts, such as the \"Flumplenook\" plant and \"sparklesynthesis,\" further undermines the credibility of the methodology. Overall, the section is incoherent and fundamentally flawed, making it unpublishable in its current form.\n",
            "The score that i finally got is 0.0\n",
            "Publishability?0, about to perform task2 if necessary.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R002.pdf 0 na na\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section appears to be a collection of unrelated concepts, theories, and techniques thrown together without a clear logical flow or connection. The text jumps abruptly from discussing the analysis of metals to topics such as soufflés, ornithology, botanical gardens, and cinematic techniques, making it challenging to discern a coherent methodology. The lack of clarity and consistency in the methodology section renders it incoherent and fundamentally flawed.\n",
            "The score that i finally got is 0.0\n",
            "Publishability?0, about to perform task2 if necessary.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R003.pdf 0 na na\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is moderately coherent, with a clear description of the experimental framework, including the development of a novel biopolymer extraction protocol, the incorporation of an unconventional approach using sound waves, and the investigation of various additives on the biopolymer's performance. However, there are some gaps and unclear steps, such as the lack of detailed information on the specific conditions and parameters used in the experiments, which may make it difficult to fully understand and replicate the methodology.\n",
            "The score that i finally got is 0.5\n",
            "Publishability?0, about to perform task2 if necessary.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R004.pdf 0 na na\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear explanation of the experimental setup, participant training, and data collection process. The use of a diverse group of participants and the introduction of ambient music as a variable add complexity to the study, but the authors do a good job of explaining how these elements fit into the overall design. The section is logically consistent, and the steps are well-connected. However, there are some areas where the explanation could be more detailed, such as the specifics of the LSTM-based gesture forecasting model and how it was trained. Additionally, some sections, such as the unplanned intrusion by the wild flamenco enthusiasts, feel slightly disconnected from the rest of the methodology. Overall, the methodology is well-explained, but could benefit from some additional clarity and detail in a few areas.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain**: Machine Learning and Human-Computer Interaction\n",
            "\n",
            "**Conference Classification**: NeurIPS (Neural Information Processing Systems)\n",
            "\n",
            "**Explanation**: The paper explores the application of LSTM-based gesture forecasting in augmented dance performances, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves predicting dancers' gestures and correlating accuracy with synchronization, emotional expression, and creativity, contributes to the advancement of machine learning techniques in human-computer interaction. The paper's interdisciplinary approach, combining flamenco dance and cutting-edge technology, also fits NeurIPS' emphasis on innovation, reproducibility, and societal impact.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R005.pdf 1 NeurIPS (Neural Information Processing Systems) The paper explores the application of LSTM-based gesture forecasting in augmented dance performances, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves predicting dancers' gestures and correlating accuracy with synchronization, emotional expression, and creativity, contributes to the advancement of machine learning techniques in human-computer interaction. The paper's interdisciplinary approach, combining flamenco dance and cutting-edge technology, also fits NeurIPS' emphasis on innovation, reproducibility, and societal impact.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear explanation of the different techniques used for aggregating temporal features in segmented video activity recognition. The section provides a logical flow of ideas, starting with the traditional approach of max- or mean-pooling, followed by alternative methods such as fixed temporal pyramid pooling and learning temporal convolution filters. The use of diagrams (Fig. 5) to illustrate the different approaches helps to enhance clarity. However, some parts of the section could be improved with more detailed explanations, such as the application of the learned filters to the video representation. Overall, the methodology is logically consistent and well-connected, but could benefit from a few additional details to make it fully understandable.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Computer Vision\n",
            "\n",
            "**Conference Classification:** CVPR\n",
            "\n",
            "**Explanation:** The paper primarily focuses on video activity recognition, proposing a novel approach that learns temporal structure filters to improve event representation. The methodology involves learning sub-events and combining them with per-class soft-attention weights, which is a significant contribution to the field of computer vision. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications aligns with the scope and values of CVPR.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/R006.pdf 1 ** CVPR ** The paper primarily focuses on video activity recognition, proposing a novel approach that learns temporal structure filters to improve event representation. The methodology involves learning sub-events and combining them with per-class soft-attention weights, which is a significant contribution to the field of computer vision. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications aligns with the scope and values of CVPR.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section presents a clear and logical flow of steps, from the multi-stage alignment method to the post-processing techniques. The use of specific techniques, such as COLMAP, SuperPoint, and SuperGlue, adds clarity to the approach. The section also effectively explains the different approaches used for simple/medium complexity cases and single-image cases. However, some minor gaps in clarity exist, such as the transition between the mesh reconstruction phase and the post-processing steps, which could be further elaborated. Overall, the methodology is well-structured and easy to follow, but could benefit from some minor refinements to achieve perfect clarity.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Computer Vision\n",
            "\n",
            "**Conference Classification:** CVPR\n",
            "\n",
            "**Explanation:** The paper primarily focuses on 3D reconstruction, mesh refinement, and scale factor estimation, which are all key areas of research in computer vision. The methodology involves the use of COLMAP, DiffusioNeRF, and NeRF2Mesh for 3D reconstruction, and the application of Laplacian Smoothing for mesh refinement, demonstrating rigorous experimentation and novel methodologies. The paper's contributions to the advancement of computer vision techniques and benchmarks align with the scope and focus of CVPR.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/R007.pdf 1 ** CVPR ** The paper primarily focuses on 3D reconstruction, mesh refinement, and scale factor estimation, which are all key areas of research in computer vision. The methodology involves the use of COLMAP, DiffusioNeRF, and NeRF2Mesh for 3D reconstruction, and the application of Laplacian Smoothing for mesh refinement, demonstrating rigorous experimentation and novel methodologies. The paper's contributions to the advancement of computer vision techniques and benchmarks align with the scope and focus of CVPR.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section presents a clear and logical flow, with each subsection building upon the previous one to provide a comprehensive analysis of the models' performance. The use of tables and figures effectively supports the discussion, making it easy to follow and understand. The authors provide a detailed analysis of the results, highlighting the strengths and weaknesses of each model. However, there are some areas where the explanation could be improved, such as the transition between the discussion of the correspondence matrices and the examination of the misclassified compounds. Overall, the methodology is well-structured and easy to follow, but could benefit from some minor clarifications to achieve perfect coherence.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain**: Natural Language Processing\n",
            "\n",
            "**Conference Classification**: EMNLP\n",
            "\n",
            "**Explanation**: The paper focuses on noun-noun compound interpretation using word embeddings and neural classification models, which aligns with the scope of EMNLP. The paper's methodology, including the use of transfer learning and multi-task learning, and its application to unseen compounds, also fit within the conference's focus on empirical methods in natural language processing.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R008.pdf 1 EMNLP The paper focuses on noun-noun compound interpretation using word embeddings and neural classification models, which aligns with the scope of EMNLP. The paper's methodology, including the use of transfer learning and multi-task learning, and its application to unseen compounds, also fit within the conference's focus on empirical methods in natural language processing.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear explanation of the data collection process, the analysis of questions and justifications, and the evaluation of the models. The section provides a logical flow of ideas, and the authors have done a good job of connecting their research design to the research questions. However, there are some areas where the methodology could be improved, such as providing more details on the specific models used and the criteria for selecting the baseline models. Additionally, some sections, such as the analysis of justifications, could be more clearly connected to the overall research goals. Overall, the methodology is clear and well-organized, but could benefit from some additional details and connections to strengthen its coherence.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 After carefully reading and analyzing the paper, I classify it as follows:\n",
            "\n",
            "**Primary Domain**: Crowdsourced Predictions and Forecasting\n",
            "\n",
            "**Conference Classification**: NeurIPS (Neural Information Processing Systems)\n",
            "\n",
            "**Explanation**: The paper focuses on aggregating crowdsourced predictions and written explanations to improve forecast accuracy, which aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves analyzing written justifications and predicting outcomes, contributes to the advancement of machine learning and AI in the field of forecasting.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R009.pdf 1 Crowdsourced Predictions and Forecasting NeurIPS (Neural Information Processing Systems)\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear logical flow. The authors effectively explain their approach to comparing localization models, including the use of the Friedman test and Wilcoxon signed-rank test with Holm's alpha correction. The section also clearly describes the hypothesis being tested and the methods used to evaluate it. However, there are some areas where the methodology could be improved, such as providing more detail on the specific models being compared and the data used in the analysis. Additionally, some sentences could be rephrased for better clarity. Overall, the methodology is well-presented, but could benefit from some minor refinements.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Machine Learning and Healthcare\n",
            "\n",
            "**Conference Classification:** NeurIPS (Neural Information Processing Systems)\n",
            "\n",
            "**Explanation:** The paper presents a deep learning approach for indoor localization using RSSI and wrist-worn accelerometer data, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves the development of a novel MDCSA model and its evaluation on a real-world dataset, contributes to the advancement of machine learning techniques in the healthcare domain. The paper's emphasis on practical applications and real-world relevance also fits NeurIPS' scope.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/KDD/R010.pdf 1 ** NeurIPS (Neural Information Processing Systems) ** The paper presents a deep learning approach for indoor localization using RSSI and wrist-worn accelerometer data, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves the development of a novel MDCSA model and its evaluation on a real-world dataset, contributes to the advancement of machine learning techniques in the healthcare domain. The paper's emphasis on practical applications and real-world relevance also fits NeurIPS' scope.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear explanation of the research questions, experimental design, and evaluation metrics. The authors provide a detailed description of their proposed model, PAAC, and its components, including the re-weighting contrastive objective and the multi-task training strategy. The section also includes a clear explanation of the datasets used, the experimental setup, and the evaluation procedure. However, there are some minor gaps in the explanation, such as the lack of details on the hyperparameter tuning process and the specific values used for the hyperparameters. Overall, the methodology is logically consistent and well-connected, but could benefit from a few additional details to make it fully understandable.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain**: Recommendation Systems\n",
            "\n",
            "**Conference Classification**: NeurIPS\n",
            "\n",
            "**Explanation**: The paper proposes a novel debiasing method, PAAC, which addresses popularity bias in recommendation systems using a combination of popularity-aware supervised alignment and re-weighted contrastive learning. The methodology involves optimizing representation consistency and providing additional supervisory signals for unpopular items, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence in machine learning and artificial intelligence research.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/KDD/R011.pdf 1 NeurIPS The paper proposes a novel debiasing method, PAAC, which addresses popularity bias in recommendation systems using a combination of popularity-aware supervised alignment and re-weighted contrastive learning. The methodology involves optimizing representation consistency and providing additional supervisory signals for unpopular items, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence in machine learning and artificial intelligence research.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section presents a clear and logical flow, with well-defined concepts and a consistent structure. The authors provide a detailed explanation of their approach, including the construction of constrained predictors, the use of proximity functions, and the combination of predictions using a convex combination. The notation and mathematical expressions are well-defined and easy to follow. The authors also provide a clear explanation of how the safe predictor is constructed and how it guarantees the satisfaction of input-output specifications. The only minor drawback is that some readers may find the notation and mathematical expressions dense and require close attention to follow. Overall, the methodology is well-presented, logical, and easy to understand, making it suitable for publication.\n",
            "The score that i finally got is 0.9\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain**: Machine Learning\n",
            "\n",
            "**Conference Classification**: NeurIPS\n",
            "\n",
            "**Explanation**: The paper presents a novel approach for designing neural networks that adhere to input-output specifications, ensuring safety and robustness in safety-critical applications. The methodology involves constructing constrained predictors and combining them using a convex combination of their predictions. This aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence, particularly in the area of machine learning and artificial intelligence.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R012.pdf 1 NeurIPS The paper presents a novel approach for designing neural networks that adhere to input-output specifications, ensuring safety and robustness in safety-critical applications. The methodology involves constructing constrained predictors and combining them using a convex combination of their predictions. This aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence, particularly in the area of machine learning and artificial intelligence.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section presents a clear and well-structured approach to evaluating the generalization error of a hypothesis function. The authors define key concepts, such as the sample operator and empirical risk, and provide a logical flow of ideas, including the introduction of the Neural Restricted Isometry Property (NeuRIPs) and its relation to the expected risk. The section also includes specific theorems and proofs, which adds to the clarity and coherence of the methodology. However, there are some areas where the explanation could be improved, such as the transition between Theorem 1 and Theorem 3, which feels a bit abrupt. Additionally, some of the mathematical expressions and notations could be further clarified for better understanding. Overall, the methodology is well-organized and easy to follow, but could benefit from some minor refinements to achieve perfect clarity.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain**: Machine Learning\n",
            "\n",
            "**Conference Classification**: NeurIPS\n",
            "\n",
            "**Explanation**: The paper introduces the Neural Restricted Isometry Property (NeuRIPs) and provides bounds on the sample complexity necessary to achieve NeuRIPs, which ensures uniform concentration of shallow ReLU networks. This work advances the state-of-the-art in machine learning by providing a theoretical framework for understanding the generalization error of neural networks, making it a strong fit for NeurIPS.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R013.pdf 1 NeurIPS The paper introduces the Neural Restricted Isometry Property (NeuRIPs) and provides bounds on the sample complexity necessary to achieve NeuRIPs, which ensures uniform concentration of shallow ReLU networks. This work advances the state-of-the-art in machine learning by providing a theoretical framework for understanding the generalization error of neural networks, making it a strong fit for NeurIPS.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with a clear logical flow. The authors provide a comprehensive overview of the concepts and techniques used, including the convergence of the OGDA method, Minty solutions, and negative comonotonicity. The section is well-connected, and the authors successfully build upon previously introduced ideas. However, there are some areas where the explanation could be improved, such as the transition between the discussion of interaction dominance and the introduction of optimism. Additionally, some technical terms and concepts could be further clarified for better understanding. Overall, the methodology is logically consistent and well-explained, but could benefit from some minor refinements.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Machine Learning\n",
            "\n",
            "**Conference Classification:** NeurIPS\n",
            "\n",
            "**Explanation:** The paper addresses min-max optimization problems, which is a fundamental topic in machine learning, and proposes novel methodologies for solving nonconvex-nonconcave problems with weak Minty solutions. The paper's focus on optimization algorithms, theoretical foundations, and practical applications aligns with NeurIPS' scope and values innovation, reproducibility, and societal impact.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/TMLR/R014.pdf 1 ** NeurIPS ** The paper addresses min-max optimization problems, which is a fundamental topic in machine learning, and proposes novel methodologies for solving nonconvex-nonconcave problems with weak Minty solutions. The paper's focus on optimization algorithms, theoretical foundations, and practical applications aligns with NeurIPS' scope and values innovation, reproducibility, and societal impact.\n",
            "Inside Perform_Tasks rn, about to perform task1\n",
            "Task1 has finished\n",
            "The task1_ans i got is The methodology section is well-structured and easy to follow, with clear definitions of key concepts and a logical flow of ideas. The authors provide a thorough explanation of the diffusion model, including the forward and backward processes, and the loss function. The theorem and lemma are also well-presented and easy to understand. However, there are some minor gaps in the explanation, such as the lack of detail on how the upper bound on W1(µ, µθ n) is derived, and some assumptions are not fully explained. Overall, the methodology is clear and well-presented, but could benefit from a bit more detail and clarification in some areas.\n",
            "The score that i finally got is 0.8\n",
            "Inside the if case of the score being greater than threshold.\n",
            "Publishability?1, about to perform task2 if necessary.\n",
            "Performing task2 now.\n",
            "Returning the following value after finishing task2 **Primary Domain:** Machine Learning\n",
            "\n",
            "**Conference Classification:** NeurIPS\n",
            "\n",
            "**Explanation:** This paper fits the scope of NeurIPS as it contributes to the advancement of machine learning research, particularly in the area of deep generative models. The paper proposes a novel approach to analyzing the convergence of denoising diffusion probabilistic models, providing a quantitative upper bound on the Wasserstein distance between the learned distribution and the target distribution. The methodology is grounded in mathematical foundations, and the paper's focus on theoretical contributions and practical implications aligns with NeurIPS' emphasis on innovation, reproducibility, and societal impact.\n",
            "The values being written are:  /content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/TMLR/R015.pdf 1 ** NeurIPS ** This paper fits the scope of NeurIPS as it contributes to the advancement of machine learning research, particularly in the area of deep generative models. The paper proposes a novel approach to analyzing the convergence of denoising diffusion probabilistic models, providing a quantitative upper bound on the Wasserstein distance between the learned distribution and the target distribution. The methodology is grounded in mathematical foundations, and the paper's focus on theoretical contributions and practical implications aligns with NeurIPS' emphasis on innovation, reproducibility, and societal impact.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "filenames=[\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R001.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R002.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R003.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R004.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Non-Publishable/R005.pdf\",\n",
        "\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/R006.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/CVPR/R007.pdf\",\n",
        "\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R008.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/EMNLP/R009.pdf\",\n",
        "\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/KDD/R010.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/KDD/R011.pdf\",\n",
        "\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R012.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/NeurIPS/R013.pdf\",\n",
        "\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/TMLR/R014.pdf\",\n",
        "    \"/content/drive/MyDrive/KDSH_2025_Dataset/Reference/Publishable/TMLR/R015.pdf\"\n",
        "]\n",
        "\n",
        "\n",
        "reference_csv_file_results=\"reference_results.csv\"\n",
        "headers = [\"Paper ID\", \"Publishable\", \"Conference\", \"Rationale\"]\n",
        "\n",
        "with open(reference_csv_file_results, mode='w', newline='', encoding='utf-8') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(headers)\n",
        "\n",
        "  for file_path in filenames:\n",
        "    task1_res, task2_res=Perform_Tasks(file_path)\n",
        "\n",
        "    conference_classification=\"na\"\n",
        "    reasoning=\"na\"\n",
        "    if(task2_res!=\"na\"):\n",
        "      response_text = task2_res\n",
        "      lines = response_text.splitlines()\n",
        "      conference_classification = lines[2].split(\":\")[1].strip()\n",
        "      reasoning = lines[4].split(\":\")[1].strip()\n",
        "\n",
        "    print(\"The values being written are: \", file_path, task1_res, conference_classification, reasoning)\n",
        "    writer.writerow([file_path, task1_res, conference_classification, reasoning])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dnUTh-1qGd2"
      },
      "source": [
        "### Merging the split csvs and formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDb7nevzqP07",
        "outputId": "3b8ad364-cce5-40c8-b881-7ddda51b36f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P001', '1', '** CVPR', \"** The paper proposes a clustering-based learning method, CL-Det, for drone detection and position estimation using LiDAR data. The approach involves processing 3D point cloud data from LiDAR sensors, applying DBSCAN clustering, and estimating the drone's position. This aligns with CVPR's focus on advancements in computer vision techniques, particularly in 3D vision and object detection, making it a suitable fit for this conference.\"]\n",
            "The row being written into the final file is ['P002', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P003', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P004', '1', 'NeurIPS', \"The paper introduces a novel concept of training-free graph neural networks (TFGNNs) that can function immediately without any training and can optionally be enhanced through subsequent training. The methodology involves using labels as features (LaF) to improve the representational capacity of GNNs. This aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence in machine learning and AI.\"]\n",
            "The row being written into the final file is ['P005', '1', '** CVPR', \"** The paper presents a framework for jointly parsing a collection of clothing images using image-level tags, which aligns with CVPR's focus on computer vision and pattern recognition. The methodology involves iterative co-segmentation and co-labeling phases, demonstrating rigorous experimentation and novel methodologies. The paper's emphasis on practical applications in clothing parsing and its use of image processing techniques make it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P006', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P007', '1', 'EMNLP', \"The paper presents a neural-based incremental parser that can jointly parse at both constituency and discourse levels, which aligns with the focus of EMNLP on empirical methods in natural language processing. The paper's methodology, which uses a bi-directional LSTM model to evaluate span boundary features, and its application to discourse parsing tasks, fit well within the scope of EMNLP. The paper's contributions to the NLP field, including its end-to-end parsing approach and handling of multi-branching discourse nodes, make it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P008', '1', 'EMNLP', \"The paper focuses on Chain-of-Thought (CoT) prompting, a technique that enhances language models' performance on complex reasoning tasks by decomposing them into simpler steps. The research investigates how CoT improves in-context learning of compositional functions, particularly multi-layer perceptrons (MLPs), and its impact on sample complexity, approximation power, and generalization capabilities. This aligns with EMNLP's focus on empirical methods in natural language processing, specifically in areas like language understanding, reasoning, and compositional functions.\"]\n",
            "The row being written into the final file is ['P009', '1', 'NeurIPS', \"The paper primarily focuses on machine learning, specifically on online prediction using RFF GPs and combining different linear basis expansions. It introduces the E-DOEBE model, which mitigates the issue of premature collapse of BMA weights, and demonstrates its effectiveness in combining dynamic and static models of different basis expansions. This aligns with NeurIPS' scope of advancing the state-of-the-art in machine learning or AI, emphasizing both theoretical and practical significance.\"]\n",
            "The row being written into the final file is ['P010', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper introduces a novel reinforcement learning approach, Model-Based Counterfactual Advantage Learning (MBCAL), to optimize long-term user satisfaction in recommender systems. The methodology leverages model-based reinforcement learning and incorporates concepts from counterfactual comparisons to enhance sample efficiency and reduce variance. This aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence in machine learning and artificial intelligence research.\"]\n",
            "The row being written into the final file is ['P011', '1', '** TMLR (Transactions on Machine Learning Research)', \"** The paper proposes two methods, HTE-BH and HTE-Knockoff, for detecting heterogeneous treatment effects in large-scale experiments, which aligns with TMLR's focus on machine learning research that balances theoretical depth and practical relevance. The paper's contributions to the machine learning community, including its emphasis on controlling the false discovery rate and addressing the multiple testing problem, make it a good fit for TMLR.\"]\n",
            "The row being written into the final file is ['P012', '1', 'NeurIPS', \"The paper explores the relationship between model parameters, compute, and loss in the context of transformer models, which is a fundamental problem in machine learning. The methodology involves analyzing the scaling laws of different components of the model and their impact on the loss function, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence. The paper's contributions to the understanding of the interplay between model parameters, compute, and loss make it a good fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P013', '1', 'EMNLP', \"The paper focuses on explaining deep neural networks in the language domain, specifically demonstrating the application of PatternAttribution to identify meaningful signal contributions in text inputs. The methodology involves training a CNN text classifier on a subset of the Amazon review polarity dataset and using PatternAttribution to retrieve neuron-wise signal contributions. This aligns with EMNLP's focus on empirical methods in natural language processing, particularly in text understanding and sentiment analysis.\"]\n",
            "The row being written into the final file is ['P014', '1', 'CVPR', \"The paper proposes a novel approach for active speaker detection in audio-visual datasets, utilizing a 3D convolutional neural network (CNN) for feature extraction and an ensemble of temporal convolution and LSTM classifiers. The methodology and application area align with CVPR's focus on advancements in computer vision techniques, particularly in image and video processing, and multimodal learning. The paper's emphasis on rigorous experimentation and practical applications also matches CVPR's conference themes.\"]\n",
            "The row being written into the final file is ['P015', '1', '** CVPR', \"** The paper focuses on 3D object detection and trajectory prediction in the domain of autonomous driving, which aligns with the scope of CVPR. The paper proposes novel methodologies, including a bottom-up network for generating proposals, a PointsPool layer, and a prediction head, which demonstrate rigorous experimentation and practical applications. The paper's contributions to computer vision techniques and benchmarks make it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P016', '1', '** None of the above conferences (CVPR, NeurIPS, EMNLP, TMLR, KDD)', \"** The paper does not fit into any of the specified conferences as it does not address topics related to computer vision, machine learning, natural language processing, or data mining. Instead, it explores the realm of interstellar diplomacy, morality, and Bayesian inference, which is not within the scope of the provided conferences. The paper's focus on developing a framework for predicting the probability of shared moral frameworks with alien civilizations and its discussion of moral harmonic resonance and quantum moral entanglement make it unsuitable for classification into any of the specified conferences.\"]\n",
            "The row being written into the final file is ['P017', '1', '** CVPR', \"** The paper presents a novel unsupervised framework for video highlight detection and summarization, which aligns with the scope of CVPR. The methodology involves leveraging crowdsourced time-synchronized comments to identify highlights and uses techniques such as lag calibration, concept mapping, and emotion concentration. The paper's focus on video processing, object detection, and multimodal learning makes it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P018', '1', '** NeurIPS', \"** The paper presents a novel approach to address plasticity loss in deep reinforcement learning agents, proposing a framework that proactively diagnoses, mitigates, and adapts to plasticity loss without substantial computational overhead. The methodology involves a combination of architectural modifications, regularization techniques, and meta-learning approaches, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence in machine learning and AI. The paper's contributions to the advancement of reinforcement learning and its practical implications make it a strong fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P019', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper focuses on developing a machine learning model to predict patient adherence to tuberculosis treatment using digital adherence technologies. The methodology involves training a deep learning model to predict the likelihood of patients missing doses and identifying high-utility interventions. The paper's emphasis on advancing the state-of-the-art in machine learning for healthcare applications, particularly in tuberculosis treatment, aligns with NeurIPS' focus on novel theories, architectures, and algorithms with strong mathematical foundations or empirical evidence in interdisciplinary applications.\"]\n",
            "The row being written into the final file is ['P020', '1', 'NeurIPS', \"The paper presents a novel approach to 3D protein structure prediction using deep learning techniques, specifically leveraging a bespoke ensemble of convolutional neural networks and recurrent neural networks. The methodology involves training a generative model on a dataset of protein structures inspired by fractal patterns, which is an unconventional and innovative approach. This aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence, and its emphasis on innovation, reproducibility, and societal impact.\"]\n",
            "The row being written into the final file is ['P021', '1', '** CVPR', \"** The paper focuses on vehicle motion prediction, which is a key area in computer vision. The methodology involves designing a novel architecture with a self-attention mechanism and a specifically designed loss function to address the domain shift problem. The paper's emphasis on predicting vehicle trajectories from raster images, its use of convolutional backbones, and its evaluation on metrics like ADE and FDE align well with the scope of CVPR, which values contributions with rigorous experimentation, novel methodologies, and practical applications in computer vision.\"]\n",
            "The row being written into the final file is ['P022', '1', '** None of the above conferences', \"** The paper explores the intersection of urban farming, insect-inspired swarm robotics, and sociobiology, focusing on drone dance rituals and their impact on crop yields, soil quality, and the local microclimate. While the paper touches on aspects of machine learning and robotics, its primary focus is on the application of swarm intelligence in agriculture, which doesn't align with the specific themes and scopes of the provided conferences.\"]\n",
            "The row being written into the final file is ['P023', '1', '** CVPR', \"** The paper presents a novel reverse hierarchy model for predicting eye fixations in images, which aligns with the scope of CVPR as a premier conference in computer vision and pattern recognition. The paper's focus on image processing, saliency detection, and visual attention, along with its rigorous experimentation and practical applications, makes it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P024', '1', 'NeurIPS', \"The paper presents a novel label-only backdoor attack, FLIP, which manipulates training labels to implant backdoors in machine learning models. The paper's focus on developing a new attack vector, analyzing its effectiveness, and exploring defense mechanisms aligns with NeurIPS' emphasis on novel theories, architectures, and algorithms with strong mathematical foundations or empirical evidence. The paper's contributions to the advancement of machine learning security and its potential impact on the field make it a good fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P025', '1', '** CVPR', \"** The paper presents a novel approach to scene parsing, which is a fundamental problem in computer vision. The methodology involves combining likelihood scores from multiple probabilistic classifiers and integrating semantic context into the parsing procedure. The paper's focus on image parsing, scene understanding, and semantic labeling aligns well with the scope of CVPR, which values contributions in computer vision techniques and benchmarks.\"]\n",
            "The row being written into the final file is ['P026', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P027', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on learning emoji representations from their descriptions, which falls under the scope of natural language processing. The methodology involves training emoji embeddings using Unicode descriptions, and the paper demonstrates the effectiveness of these embeddings in a sentiment analysis task on Twitter data. This aligns with EMNLP's focus on empirical methods in NLP, particularly in areas like text understanding and sentiment analysis.\"]\n",
            "The row being written into the final file is ['P028', '1', 'EMNLP', \"The paper presents a novel framework for resolving structural ambiguities in multimodal contexts, focusing on visually grounded language processing. It introduces a unified approach for disambiguating descriptions of videos, which aligns with EMNLP's focus on empirical methods in natural language processing. The paper's emphasis on multimodal learning, linguistic and visual interpretations, and ambiguity resolution makes it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P029', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper introduces OpenOmni, an open-source, end-to-end multimodal pipeline that integrates advanced technologies such as Speech-to-Text, Emotion Detection, Retrieval Augmented Generation, and Large Language Models. The paper's focus on natural language processing, multimodal interaction, and conversational agents aligns with EMNLP's scope, which values innovative approaches that address challenges in NLP, including multilingual processing, large-scale data processing, and interpretability. The paper's emphasis on empirical methods, robust experimental design, and real-world language applications further supports its classification under EMNLP.\"]\n",
            "The row being written into the final file is ['P030', '1', '** NeurIPS', \"** The paper presents a novel approach to memory optimization for dynamic shape graphs in deep learning tasks, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which utilizes symbolic shapes and a hybrid compilation-runtime approach, contributes to the advancement of machine learning techniques and demonstrates practical applications in reducing memory consumption.\"]\n",
            "The row being written into the final file is ['P031', '1', 'EMNLP', \"The paper proposes a novel approach to identify and explain hate speech towards Islam using Graph Neural Networks (GNNs), which aligns with the scope of EMNLP as it focuses on empirical methods in natural language processing. The paper's methodology, which involves representing speeches as nodes and connecting them with edges based on context and similarity, and leveraging GNNs to understand the context and patterns of hate speech, is a significant contribution to the NLP field.\"]\n",
            "The row being written into the final file is ['P032', '0', 'na', 'na']\n",
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P033', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper presents a transition-based AMR parser that directly generates AMR parses from plain text, which aligns with EMNLP's focus on empirical methods in natural language processing. The paper's methodology, which uses Stack-LSTMs to represent the parser state and make decisions greedily, contributes to the advancement of the NLP field with robust experimental design and innovative architectures. The paper's application to AMR parsing, a key area in NLP, further supports its relevance to EMNLP.\"]\n",
            "The row being written into the final file is ['P034', '1', '** CVPR', \"** The paper primarily focuses on computer vision tasks, such as image classification, semantic segmentation, and object detection, using Vision Transformers (ViT) and proposes a novel technique called Dynamic Positional Normalization (DPN) to improve the performance of ViT models. The paper demonstrates rigorous experimentation on various benchmarks, including ImageNet, ADE20K, and VTAB, which aligns with CVPR's emphasis on advancements in computer vision techniques and benchmarks.\"]\n",
            "The row being written into the final file is ['P035', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P036', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P037', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P038', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper explores the application of Graph Neural Networks (GNNs) to predict caffeine diffusion patterns in holographically prepared espresso foam, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence. The paper's methodology, which involves the use of GNNs to model complex systems, and its interdisciplinary approach to materials science and espresso foam, make it a strong fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P039', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P040', '1', '** CVPR', \"** The paper introduces a 3D Convolutional Neural Network (CNN) approach for sustainable architectural design through computational fluid dynamics simulation and reverse design workflow. The methodology involves using residual CNNs for near real-time prediction of steady turbulent flow within a 3D environment, which aligns with CVPR's focus on advancements in computer vision and pattern recognition. The paper demonstrates rigorous experimentation, novel methodologies, and practical applications, making it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P041', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper aligns with NeurIPS due to its focus on reinforcement learning, metaverse ecology, and the integration of ancient conspiracy theories with machine learning. The methodology involves training an agent on a bespoke corpus of ancient texts, folklore, and speculative literature, which demonstrates a novel approach to machine learning and AI. The paper's emphasis on innovation, reproducibility, and societal impact also aligns with NeurIPS' values.\"]\n",
            "The row being written into the final file is ['P042', '1', '** CVPR', \"** The paper proposes a novel semantic similarity metric for image registration, which aligns with CVPR's focus on advancements in image and video processing. The methodology involves training a feature extractor on a segmentation task to learn semantically relevant features, and the paper demonstrates improved registration accuracy and faster convergence on biomedical datasets. This contribution fits CVPR's emphasis on rigorous experimentation, novel methodologies, and practical applications in computer vision.\"]\n",
            "The row being written into the final file is ['P043', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P044', '1', 'CVPR', \"The paper focuses on crop yield predictions using deep learning models, specifically ConvLSTM, CNN-RNN, GNN-RNN, and MMST-ViT, which are all computer vision and machine learning techniques. The paper's methodology involves experimenting with these models on the CropNet dataset, which consists of satellite images and meteorological data, demonstrating the application of computer vision and machine learning in agriculture. The paper's significance lies in its contribution to the advancement of computer vision techniques and benchmarks in the context of crop yield prediction, making it a good fit for CVPR.\"]\n",
            "The row being written into the final file is ['P045', '1', '** CVPR', \"** The paper introduces a novel approach to multi-teacher distillation, proposing a unified model that amalgamates the strengths of various visual foundation models. The methodology involves iterative learning, heavy augmentation, and pseudo-labeling, demonstrating rigorous experimentation and practical applications in computer vision. The paper's focus on image processing, object detection, and visual understanding, along with its emphasis on scalability and real-world relevance, aligns well with the scope of CVPR.\"]\n",
            "The row being written into the final file is ['P046', '1', 'NeurIPS', \"The paper focuses on the adversarial robustness of Graph Neural Networks (GNNs) and proposes a novel symbiotic attack that combines both evasion and poisoning attacks. The methodology involves developing a memory-efficient adaptive end-to-end attack using first-order optimization, which aligns with NeurIPS' focus on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence. The paper's contributions to the machine learning field, particularly in the area of graph neural networks, make it a strong fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P047', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P048', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P049', '1', '** CVPR', \"** The paper focuses on improving the robustness of semantic segmentation models in the domain generalization setting, which aligns with CVPR's scope of advancements in computer vision techniques and benchmarks. The paper proposes a novel self-adaptive inference process that updates model parameters during inference, demonstrating rigorous experimentation and practical applications in computer vision. The paper's emphasis on visual understanding, segmentation accuracy, and robustness to domain shifts makes it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P050', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on interpreting and explaining the behavior of deep learning models in natural language inference tasks, specifically analyzing the attention and gating signals in LSTM-based models. The methodology involves visualizing saliency curves to understand the importance of different parts of the sentence in making inference decisions. This aligns with EMNLP's focus on empirical methods in NLP, particularly in areas like text understanding and sentiment analysis.\"]\n",
            "The row being written into the final file is ['P051', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper introduces a method for real-time unsupervised domain adaptation in part-of-speech tagging, which is a fundamental task in natural language processing. The paper's focus on empirical methods, experimental design, and real-world language applications aligns with the scope of EMNLP. The paper's contribution to the NLP field, particularly in domain adaptation, makes it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P052', '1', 'NeurIPS (Neural Information Processing Systems)', \"The paper focuses on developing a novel neural network architecture (ADNN) for feature extraction from financial time series data, which aligns with NeurIPS' scope of machine learning and deep learning research. The paper's methodology involves designing a specific network structure, loss function, and training process to improve the performance of quantitative investment strategies, demonstrating a strong connection to NeurIPS' emphasis on novel theories, architectures, and algorithms with strong mathematical foundations or empirical evidence.\"]\n",
            "The row being written into the final file is ['P053', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P054', '1', '** CVPR', \"** The paper focuses on 3D food modeling from images, which is a topic closely related to computer vision and pattern recognition. The methodology involves physically informed 3D food reconstruction, leveraging recent progress in 3D reconstruction technologies, which aligns with CVPR's scope of advancements in image and video processing, object detection, and 3D vision. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications also matches CVPR's expectations.\"]\n",
            "The row being written into the final file is ['P055', '1', 'NeurIPS', \"The paper explores the initial experiences of researchers when articulating broader impact statements in AI research, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves a survey of researchers, and its emphasis on ethical practices and societal impact, also fit well with NeurIPS' scope.\"]\n",
            "The row being written into the final file is ['P056', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P057', '1', '** CVPR', '** The paper introduces a novel approach to human-machine interaction in a collaborative painting experience, utilizing a neural sketcher to partially complete the artwork. The methodology involves image processing, stroke analysis, and generative models, which aligns with the scope of CVPR. The paper demonstrates rigorous experimentation, novel methodologies, and practical applications in computer vision and pattern recognition, making it a strong fit for CVPR.']\n",
            "The row being written into the final file is ['P058', '1', 'EMNLP', \"The paper focuses on the reverse-ordering task in natural language processing, exploring the effects of positional encoding on RNNs and S4D models in handling large vocabularies. The methodology involves novel experiments with non-uniformly distributed tokens to examine the relationship between token frequency and RNN performance. The paper's contributions to the NLP field, including robust experimental design and innovative architectures, align with EMNLP's focus on empirical methods in natural language processing.\"]\n",
            "The row being written into the final file is ['P059', '1', '** EMNLP (Empirical Methods in Natural Language Processing)', \"** The paper focuses on the challenges of training RNNs with large vocabularies, specifically examining the impact of token frequency on RNN performance and proposing positional encoding as a solution. The paper's emphasis on empirical methods, thorough experimentation, and real-world language applications aligns with EMNLP's scope and values.\"]\n",
            "The row being written into the final file is ['P060', '1', '** CVPR', \"** The paper focuses on background modeling and foreground detection in video sequences, which is a fundamental problem in computer vision. The methodology involves adapting kernel variances for each pixel, incorporating complex features like SILTP, and using a caching scheme to improve speed. The paper's contributions, such as the practical scheme for pixel-wise variance selection and the incorporation of SILTP features, align well with CVPR's scope of advancing computer vision techniques and benchmarks.\"]\n",
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P061', '1', '** CVPR', \"** The paper primarily focuses on contrastive instance discrimination techniques in computer vision, exploring the effectiveness of different augmentation strategies and their impact on representation learning. The methodology involves comparing the performance of various approaches, including MoCo-v2 and CLSA, on ImageNet-1K and other datasets, which aligns with CVPR's emphasis on advancements in image and video processing, object detection, and visual understanding. The paper's rigorous experimentation and practical applications in object detection and related tasks further support its classification under CVPR.\"]\n",
            "The row being written into the final file is ['P062', '1', '** CVPR', \"** The paper presents a novel method for adapting large pretrained models to new tasks while preserving their inherent equivariance properties, which is a crucial aspect of computer vision. The paper's focus on image classification, object detection, and regression tasks, along with its emphasis on equivariance preservation, aligns well with CVPR's scope of advancements in computer vision techniques and benchmarks. The paper's rigorous experimentation and practical applications also match CVPR's values.\"]\n",
            "The row being written into the final file is ['P063', '1', 'NeurIPS', \"The paper studies the layer-wise transferability of representations in deep neural networks across several datasets and tasks, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves empirical observations and analysis of the characteristics of datasets and tasks, also fits well with NeurIPS' emphasis on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence.\"]\n",
            "The row being written into the final file is ['P064', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on empowering open-source large language models (LLMs) to effectively utilize multi-modal tools for tasks involving visual comprehension and image generation. The methodology involves a novel self-instruction framework that enables these models to learn to utilize a diverse range of tools, both seen and unseen, in zero-shot and fine-tuning settings. This aligns with EMNLP's focus on empirical methods in NLP, particularly in the areas of text generation, understanding, and multilingual NLP.\"]\n",
            "The row being written into the final file is ['P065', '1', 'CVPR', \"The paper investigates the effects of recursive inpainting on Stable Diffusion, a widely used image model, and explores the conditions under which the model maintains stability or degrades. The paper's focus on image generation, inpainting, and the evaluation of image quality metrics (e.g., LPIPS) aligns with the scope of CVPR, which values contributions with rigorous experimentation, novel methodologies, and practical applications in computer vision.\"]\n",
            "The row being written into the final file is ['P066', '1', 'EMNLP', \"The paper focuses on language model compression, vocabulary transfer, and knowledge distillation, which are all key topics in natural language processing. The methodology involves experimenting with different tokenizers and evaluating their impact on performance, compression rate, and inference speed, which aligns with EMNLP's focus on empirical methods in NLP. The paper's contributions to the NLP field, including its experimental design and innovative approaches to language model compression, make it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P067', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper introduces a novel Python API that facilitates access to the FrameNet 1.7 lexical database, enabling programmatic processing of the lexicon and annotated sentences. This work advances the state-of-the-art in natural language processing by providing a user-friendly interface for browsing and exploring FrameNet data, which is a significant resource for semantic role labeling and other NLP applications. The paper's focus on developing a practical tool for NLP research aligns with NeurIPS' emphasis on innovation, reproducibility, and societal impact.\"]\n",
            "The row being written into the final file is ['P068', '1', 'CVPR', \"The paper presents a novel approach to efficient and robust 3D object detection in vehicle-to-infrastructure cooperative scenarios, leveraging feature flow and learned compression schemes. The methodology and application area align well with CVPR's focus on advancements in computer vision techniques, particularly in image and video processing, object detection, and 3D vision. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications also matches CVPR's expectations.\"]\n",
            "The row being written into the final file is ['P069', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P070', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P071', '1', 'EMNLP', \"The paper focuses on the impact of fillers in spoken language on language modeling and downstream tasks such as FOAK and stance prediction. It explores different token representation and pre-processing strategies for integrating fillers and demonstrates that retaining fillers in transcribed spoken language can improve results in language modeling and downstream tasks. This aligns with EMNLP's focus on empirical methods in natural language processing, particularly in areas such as language modeling, sentiment analysis, and multilingual NLP.\"]\n",
            "The row being written into the final file is ['P072', '1', 'NeurIPS', \"The paper evaluates the resilience of white-box defenses against adversarial examples, demonstrating the lack of effectiveness of two defenses designed to counter white-box attacks. The paper's focus on machine learning, specifically neural networks and adversarial examples, aligns with NeurIPS' scope of advancing the state-of-the-art in machine learning and AI. The paper's methodology, which involves generating targeted adversarial examples using Projected Gradient Descent, and its emphasis on the practical significance of the results, also fit well with NeurIPS' values.\"]\n",
            "The row being written into the final file is ['P073', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P074', '1', '** CVPR', \"** The paper presents a solution to the Agriculture-Vision Challenge, focusing on agricultural pattern recognition from aerial images using Transformer-based models and data augmentation techniques. The methodology involves data pre-processing, model ensemble, and test-time augmentation, demonstrating rigorous experimentation and practical applications in computer vision. The paper's emphasis on image processing, object detection, and visual understanding aligns with the scope of CVPR, making it a suitable fit for this conference.\"]\n",
            "The row being written into the final file is ['P075', '1', '** CVPR', \"** The paper focuses on adapting large pretrained models for video alignment to improve multi-step inference, which aligns with CVPR's scope of computer vision and pattern recognition. The methodology involves leveraging VideoCLIP to generate video-script alignment features, grounding question-relevant content, and reweighting multimodal context, demonstrating rigorous experimentation and novel methodologies. The paper's contributions to advancing computer vision techniques and benchmarks make it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P076', '1', '** None of the above conferences (CVPR, NeurIPS, EMNLP, TMLR, KDD)', \"** The paper does not fit into any of the specified conferences as it primarily focuses on urban transportation, sustainability, and autonomous vehicles, which is not a primary domain of any of the mentioned conferences. The paper's methodology involves interdisciplinary approaches, including transportation engineering, computer science, environmental science, and complexity theory, which does not align with the specific focus areas of the provided conferences.\"]\n",
            "The row being written into the final file is ['P077', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P078', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P079', '1', 'CVPR', \"The paper introduces OmniPrint, a synthetic data generator for printed characters, which aligns with CVPR's focus on advancements in image and video processing. The paper's methodology, which includes generating realistic small-sized images with control over font, style, and distortion parameters, demonstrates rigorous experimentation and novel methodologies, making it a good fit for CVPR. Additionally, the paper's application in machine learning research and its potential to drive progress in image classification and regression problems further supports its classification under CVPR.\"]\n",
            "The row being written into the final file is ['P080', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P081', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P082', '1', 'NeurIPS', \"The paper presents a PyTorch-based library for variational learning with disentanglement, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper contributes to the advancement of state-of-the-art in machine learning by introducing a modular library that facilitates the research, implementation, and evaluation of novel variational algorithms, with a specific emphasis on representation learning and disentanglement. The paper's methodology, which involves the development of a library with various algorithms and evaluation metrics, fits NeurIPS' scope of innovative theories, architectures, or algorithms with strong mathematical foundations or empirical evidence.\"]\n",
            "The row being written into the final file is ['P083', '1', '** NeurIPS', \"** The paper analyzes the citation patterns between Chinese and American research communities at NeurIPS, a leading venue for machine learning research. The study's focus on citation networks, institutional information, and regional preferences aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves constructing a citation graph and comparing regional connectivity, also fits NeurIPS' emphasis on novel theories, architectures, or algorithms with strong mathematical foundations or empirical evidence.\"]\n",
            "The row being written into the final file is ['P084', '1', '** Computer Vision', '** CVPR']\n",
            "The row being written into the final file is ['P085', '1', 'NeurIPS', \"The paper presents a novel approach to incorporating safety constraints into neural network predictors, which aligns with NeurIPS' focus on machine learning and deep learning research. The paper's methodology, which involves sharing layers and projecting outputs onto a convex approximation of the safe output region, contributes to the advancement of machine learning techniques. The paper's emphasis on theoretical foundations and empirical evidence also matches NeurIPS' expectations.\"]\n",
            "The row being written into the final file is ['P086', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P087', '1', 'CVPR', \"The paper presents a novel feature tracking framework that combines the low-rank geometry of feature trajectories with a non-linear single-feature tracking approach, demonstrating strong performance in rigid and non-rigid motion scenarios. The paper's focus on feature tracking, motion estimation, and robustness in low-quality video sequences aligns with CVPR's scope of advancing computer vision techniques and benchmarks. The paper's methodology, experimentation, and practical applications also match CVPR's emphasis on rigorous experimentation, novel methodologies, and real-world relevance.\"]\n",
            "The row being written into the final file is ['P088', '1', 'NeurIPS', \"The paper focuses on analyzing modularity in artificial neural networks, a topic central to understanding and improving representation learning and network design. The methodology involves mathematical definitions of functional similarity, clustering algorithms, and empirical validation on trained networks, aligning well with NeurIPS's emphasis on theoretical and empirical advancements in machine learning. The innovative exploration of upstream and downstream modularity perspectives also addresses fundamental questions about neural representations, fitting NeurIPS's focus on advancing the state-of-the-art in machine learning research.\"]\n",
            "The row being written into the final file is ['P089', '1', 'NeurIPS', \"** The paper investigates the conditions under which the neural tangent kernel (NTK) approximation remains valid when employing the square loss function for model training. It refines the earlier result from Chizat et al. and establishes the preciseness of the established bound. The paper's focus on the theoretical understanding of neural networks, the NTK approximation, and the lazy training framework aligns with NeurIPS' scope of machine learning, deep learning, and artificial intelligence research.\"]\n",
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P090', '1', '** CVPR', \"** The paper focuses on adapting large pretrained models to new tasks while preserving equivariance, which is a fundamental concept in computer vision. The methodology involves identifying group structures inherent in the data, constructing a regularization term based on group representation theory, and incorporating it into the fine-tuning loss function. The paper's emphasis on image classification, object detection, and physics simulation tasks, as well as its evaluation on datasets like CIFAR-10, ImageNet, and COCO, aligns well with the scope of CVPR, which values advancements in computer vision techniques and benchmarks.\"]\n",
            "The row being written into the final file is ['P091', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on Named Entity Recognition (NER) in call center transcripts, which is a specific application of natural language processing. The methodology involves using a BiLSTM-CRF model with custom contextual string embeddings to identify and handle sensitive personal information within call center transcripts. This aligns with EMNLP's focus on empirical methods in NLP, particularly in areas like text understanding and information extraction.\"]\n",
            "The row being written into the final file is ['P092', '1', '** CVPR', \"** The paper primarily focuses on image compression, which is a key area in computer vision. It proposes novel methodologies, such as the use of deep residual networks, sub-pixel convolution, and rate control, to improve the performance of image compression models. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications aligns well with the scope and values of CVPR.\"]\n",
            "The row being written into the final file is ['P093', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P094', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P095', '1', 'NeurIPS', \"The paper presents a novel hierarchical reinforcement learning framework, JueWu-MC, designed to play Minecraft. It introduces techniques in representation learning and imitation learning, improving both performance and learning efficiency. The paper's focus on reinforcement learning, imitation learning, and its application to a complex environment like Minecraft aligns well with NeurIPS' scope, which values innovation, reproducibility, and societal impact in machine learning and AI research.\"]\n",
            "The row being written into the final file is ['P096', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P097', '1', '** None of the above', \"** The paper does not fit neatly into any of the specified conferences, as it explores wave-like phenomena across various domains, including computer science, anthropology, sociology, physics, mechanical engineering, culinary arts, and more. The paper's methodology is highly interdisciplinary, and its applications are diverse, making it difficult to classify into a single conference. The paper's focus on understanding wave dynamics and its implications for various fields does not align with the specific themes and scopes of the provided conferences.\"]\n",
            "The row being written into the final file is ['P098', '1', 'NeurIPS (Neural Information Processing Systems)', 'The paper presents a novel approach to industrial load handling using robotic exoskeletons, which involves the integration of artificial intelligence and machine learning algorithms to adapt to various load handling scenarios. The paper\\'s focus on the development of a \"creative module\" using generative adversarial networks and the exploration of unconventional approaches such as \"neuro-exoskeletal resonance\" aligns with NeurIPS\\' emphasis on novel theories, architectures, and algorithms with strong mathematical foundations or empirical evidence.']\n",
            "The row being written into the final file is ['P099', '1', 'EMNLP', \"The paper focuses on enhancing LSTM-based video narration by incorporating linguistic insights from text datasets, which aligns with EMNLP's scope of empirical methods in natural language processing. The paper's methodology involves integrating a neural language model and distributive semantics into a video description framework, which is a novel approach in NLP. The paper's contributions to the NLP field, including its robust experimental design and innovative architectures, make it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P100', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P101', '1', 'CVPR', \"The paper proposes a novel Conv-LSTM architecture for emphysema detection in CT scans, which aligns with CVPR's focus on advancements in computer vision and pattern recognition. The methodology involves processing imaging volumes slice by slice, demonstrating rigorous experimentation and practical applications in medical imaging. The paper's contributions to computer vision techniques and benchmarks make it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P102', '1', '** CVPR', \"** The paper focuses on fine-grained car categorization and verification, which aligns with the scope of CVPR as a premier conference in computer vision and pattern recognition. The paper proposes novel methodologies, such as the CompCars dataset, and demonstrates rigorous experimentation and practical applications in car model classification, attribute prediction, and verification. The paper's contributions to advancing computer vision techniques and benchmarks, particularly in the area of fine-grained object recognition, make it a strong fit for CVPR.\"]\n",
            "The row being written into the final file is ['P103', '1', '** EMNLP', \"** The paper focuses on the task of translating natural language descriptions into executable command-line instructions, which is a core area of research in natural language processing. The paper's methodology, including the use of transformer models and the development of a new metric for evaluating the accuracy of generated commands, aligns with the empirical methods and innovative approaches valued by EMNLP. The paper's contributions to the NLP field, including its exploration of the challenges and opportunities of adapting large pretrained models for this task, make it a strong fit for EMNLP.\"]\n",
            "The row being written into the final file is ['P104', '1', 'EMNLP', \"The paper primarily focuses on improving logical consistency and performance in pre-trained language models through natural language inference (NLI). It presents a framework called ConCoRD, leveraging pre-trained NLI models for pairwise logical relationship estimation. This methodology aligns closely with EMNLP's emphasis on empirical methods, particularly in text understanding and reasoning. The robust experiments across tasks like question answering and visual question answering, combined with the innovative use of NLI models, make it a strong candidate for EMNLP.\"]\n",
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P105', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P106', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P107', '1', 'NeurIPS (Neural Information Processing Systems)', \"The paper explores the application of neural networks in weather forecasting, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's methodology, which involves the use of convolutional neural networks (CNNs), recurrent neural networks (RNNs), and generative models, is also well-suited for NeurIPS. Additionally, the paper's emphasis on advancing the state-of-the-art in weather forecasting using machine learning techniques is consistent with NeurIPS' values of innovation, reproducibility, and societal impact.\"]\n",
            "The row being written into the final file is ['P108', '1', 'EMNLP', \"The paper focuses on phonological typology, phoneme inventories, and speech processing, which aligns with the scope of EMNLP. The methodology involves evaluating the cross-linguistic consistency of phonological features and proposing a method for phoneme inventory induction, which contributes to the advancement of natural language processing. The paper's emphasis on multilingual speech processing and language documentation also fits well with EMNLP's focus on empirical methods in NLP.\"]\n",
            "The row being written into the final file is ['P109', '1', 'EMNLP', \"The paper focuses on detecting hate speech in multimodal memes, which involves natural language processing and visual understanding. The methodology involves fine-tuning pre-trained Transformer models on a dataset of labeled multimodal memes, and the paper contributes to the NLP field with robust experimental design and innovative approaches to address the challenge of hate speech detection. The paper's emphasis on empirical methods and applications in natural language processing aligns with the scope of EMNLP.\"]\n",
            "The row being written into the final file is ['P110', '1', 'EMNLP', \"The paper introduces LIDA, a lightweight interactive dialogue annotator that handles the entire dialogue annotation pipeline from raw text to structured conversation data. It integrates arbitrary machine learning models as annotation recommenders and provides a dedicated interface to resolve inter-annotator disagreements. This aligns with EMNLP's focus on empirical methods in natural language processing, particularly in dialogue systems and annotation tools.\"]\n",
            "The row being written into the final file is ['P111', '1', 'NeurIPS', \"The paper aligns with NeurIPS as it contributes to the advancement of machine learning and artificial intelligence research. The paper proposes novel methodologies, such as the use of Bayesian neural networks (BNNs) as surrogate models in Bayesian optimization, and demonstrates their effectiveness in various scientific applications. The paper's focus on innovation, reproducibility, and practical significance also aligns with NeurIPS' values.\"]\n",
            "The row being written into the final file is ['P112', '1', '** KDD (Knowledge Discovery and Data Mining)', \"** The paper presents a novel k-mer embedding technique that integrates metagenomic contextual and structural nuances, achieved through the enhancement of the De Bruijn graph and the use of contrastive learning. The methodology involves graph neural networks, self-supervised learning, and k-mer similarity calculations, which aligns with KDD's focus on scalable algorithms, applications in diverse domains, and frameworks for real-world challenges. The paper's contribution to the advancement of bioinformatics and genomics, particularly in metagenomic sequence analysis, makes it a good fit for KDD.\"]\n",
            "The row being written into the final file is ['P113', '1', 'NeurIPS (Neural Information Processing Systems)', 'The paper introduces a novel \"GNN for MBRL\" model that combines a graph neural network (GNN) dynamics model with model-based reinforcement learning to tackle multi-agent systems tasks. The methodology involves using a GNN model to predict future states and paths of several agents, and then utilizing a model predictive control (MPC) approach to guide the ego-agent\\'s action planning. This paper advances the state-of-the-art in machine learning and AI by proposing a new framework for multi-agent systems control, which aligns with NeurIPS\\' focus on innovation, reproducibility, and societal impact.']\n",
            "The row being written into the final file is ['P114', '1', 'NeurIPS (Neural Information Processing Systems)', \"The paper presents an Empathic AI Painter system that combines Deep Style techniques, Non-Photorealistic Rendering (NPR) techniques, and a generative AI portraiture module to create personalized stylized portraits. The system's ability to understand human traits like personality and emotions, and its use of AI techniques to replicate the artistic process, aligns well with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's contributions to the advancement of AI in understanding human creativity and generating artistic representations make it a good fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P115', '1', 'CVPR', \"The paper focuses on large multimodal models (LMMs) and their applications in various domains, including visual question answering, object hallucination, and optical character recognition. The methodology involves integrating visual and language models, fine-tuning, and instruction tuning, which aligns with CVPR's scope of advancements in computer vision techniques and benchmarks. The paper's emphasis on multimodal learning, visual understanding, and practical applications also fits well with CVPR's themes.\"]\n",
            "The row being written into the final file is ['P116', '1', 'NeurIPS', \"The paper presents a novel decision tree algorithm, Top-k, which explores the top k features at each node, offering a controlled trade-off between computational cost and accuracy. This approach is distinct from traditional greedy feature selection methods and ensemble techniques, making it a significant contribution to the machine learning community. The paper's focus on improving the feature selection process, its theoretical analysis, and empirical evaluation align with NeurIPS' emphasis on novel theories, architectures, and algorithms with strong mathematical foundations or empirical evidence.\"]\n",
            "The row being written into the final file is ['P117', '1', 'CVPR', \"The paper focuses on image tagging, which is a fundamental problem in computer vision. The methodology involves approximating the principal directions in the word vector space for tag assignment, and the paper demonstrates significant improvements in image tagging tasks, including conventional, zero-shot, and seen/unseen tagging scenarios. The paper's emphasis on rigorous experimentation, novel methodologies, and practical applications aligns with the scope and values of CVPR.\"]\n",
            "The row being written into the final file is ['P118', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on part-of-speech (POS) tagging, a fundamental task in natural language processing, and explores the integration of lexical information into neural models. The methodology involves evaluating different approaches to incorporating lexical knowledge, such as n-hot encoding and embedding, and demonstrates significant improvements in accuracy. The paper's emphasis on empirical methods, robust experimentation, and real-world language applications aligns with the scope of EMNLP.\"]\n",
            "The row being written into the final file is ['P119', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P120', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper introduces diagNNose, an open-source toolkit for examining activations within deep neural networks, specifically focusing on language models. The toolkit offers various interpretability methods, including targeted syntactic evaluations, diagnostic classifiers, and feature attributions. The paper's primary domain is natural language processing, and its methodology and application align with EMNLP's focus on empirical methods in NLP, making it a suitable fit for this conference.\"]\n",
            "The row being written into the final file is ['P121', '1', '** NeurIPS', \"** The paper presents a novel method for mitigating plasticity loss in reinforcement learning agents, which aligns with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research. The paper's contribution to the advancement of reinforcement learning, its rigorous experimentation, and its potential for real-world applications make it a strong fit for NeurIPS.\"]\n",
            "The row being written into the final file is ['P122', '1', 'CVPR', \"The paper focuses on precipitation detection and nowcasting using satellite imagery, which falls under the scope of computer vision and pattern recognition. The methodology involves the use of convolutional neural networks (UNet architecture) for precipitation detection, and the paper demonstrates rigorous experimentation and practical applications in the field of satellite image processing. The paper's contributions to the advancement of computer vision techniques and benchmarks align with the academic standards of CVPR.\"]\n",
            "The row being written into the final file is ['P123', '1', 'EMNLP (Empirical Methods in Natural Language Processing)', \"The paper focuses on acquiring cross-domain representations for contextual detection using extensive emoji data, which aligns with EMNLP's scope of empirical methods in natural language processing. The paper's methodology, which involves using a vast collection of emoji occurrences to acquire versatile representations applicable to diverse domains, and its application to sentiment, emotion, and sarcasm detection, fit well with EMNLP's focus on innovative approaches to NLP challenges.\"]\n",
            "The row being written into the final file is ['P124', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P125', '1', 'EMNLP', \"The paper introduces DISCOSENSE, a novel benchmark for commonsense reasoning using discourse connectives, which aligns closely with EMNLP's focus on empirical methods in NLP. The methodology combines innovative techniques like Conditional Adversarial Filtering and the use of discourse connectives for challenging reasoning tasks, demonstrating a strong experimental design. With its emphasis on understanding discourse relations and evaluating state-of-the-art language models, this work is well-suited for EMNLP's thematic scope and standards.\"]\n",
            "The type of curr_file is <class '_io.TextIOWrapper'>\n",
            "The row being written into the final file is ['P126', '1', '** TMLR (Transactions on Machine Learning Research)', \"** The paper proposes a novel algorithm for causal effect estimation in linear Structural Causal Models (SCMs) with latent confounders, leveraging a single proxy variable and cross-moments. This research aligns with TMLR's focus on machine learning research that balances theoretical depth and practical relevance, particularly in the area of causal inference. The paper's contribution to the ML community, with its emphasis on theoretical foundations and empirical validation, makes it a strong fit for TMLR.\"]\n",
            "The row being written into the final file is ['P127', '1', '** NeurIPS (Neural Information Processing Systems)', \"** The paper explores the intersection of machine learning and privacy, discussing the potential threats to personal privacy posed by machine learning systems and proposing strategies to counter these threats. The paper's focus on the societal implications of machine learning, its emphasis on the need for collaboration between machine learning experts and human-computer interaction researchers, and its discussion of auditing and regulation as means to resist surveillance technologies align well with NeurIPS's scope and values.\"]\n",
            "The row being written into the final file is ['P128', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P129', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P130', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P131', '1', '** CVPR', \"** The paper focuses on enhancing disentanglement through learned aggregation of convolutional feature maps, which is a significant advancement in computer vision techniques. The methodology involves fine-tuning a feature extraction network and training a VAE to reconstruct feature vectors and disentangle latent factors of variation. This aligns with CVPR's scope of addressing advancements in image and video processing, object detection, and generative models, making it a strong fit for this conference.\"]\n",
            "The row being written into the final file is ['P132', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P133', '1', 'EMNLP', \"The paper focuses on parsing as sequence labeling, which is a fundamental task in natural language processing. The authors propose various encoding schemes to represent syntactic trees as sequences of labels, and experiment with different neural architectures to learn these encodings. The paper's emphasis on empirical methods, experimental design, and real-world language applications aligns well with the scope of EMNLP.\"]\n",
            "The row being written into the final file is ['P134', '0', 'na', 'na']\n",
            "The row being written into the final file is ['P135', '1', '** NeurIPS', \"** The paper proposes a decentralized local stochastic extragradient approach for variational inequalities, which is a novel algorithm for solving decentralized stochastic saddle-point problems. The methodology and application of the paper align with NeurIPS' focus on machine learning, deep learning, and artificial intelligence research, particularly in the areas of optimization, reinforcement learning, and generative AI. The paper's contribution to the advancement of machine learning techniques and its practical applications in training decentralized GANs make it a strong fit for NeurIPS.\"]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "merge_file_names=[\n",
        "    \"1_32_inclusive_results.csv\",\n",
        "    \"33_60_inclusive_results.csv\",\n",
        "    \"61_89_inclusive_results.csv\",\n",
        "    \"90_104_inclusive_results.csv\",\n",
        "    \"105_125_inclusive_results.csv\",\n",
        "    \"126_135_inclusive_results.csv\"\n",
        "]\n",
        "\n",
        "final_submission_csv=\"final_results.csv\"\n",
        "headers = [\"Paper ID\", \"Publishable\", \"Conference\", \"Rationale\"]\n",
        "\n",
        "with open(final_submission_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow(headers)\n",
        "\n",
        "  for csv_file in merge_file_names:\n",
        "    with open(csv_file, mode='r', newline='', encoding='utf-8') as curr_file:\n",
        "      print(\"The type of curr_file is\", type(curr_file))\n",
        "      reader=csv.reader(curr_file)\n",
        "      next(reader)\n",
        "      for row in reader:\n",
        "        print(\"The row being written into the final file is\", row)\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28L2QFA-gq_Z"
      },
      "source": [
        "## Formatting the excel code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jCMlBR3LgtAp",
        "outputId": "b6be21c6-a446-4a63-c03d-df2658160195"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'updated_cleaned_final_results.csv'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = 'final_results.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#Cleaning logic for the \"Conference\" cells.\n",
        "def clean_conference(cell):\n",
        "  if \"None of the above conferences\" in cell:\n",
        "    return \"na\"\n",
        "  elif \"NeurIPS\" in cell:\n",
        "    return \"neurips\"\n",
        "  elif \"CVPR\" in cell:\n",
        "    return \"cvpr\"\n",
        "  elif \"EMNLP\" in cell:\n",
        "    return \"emnlp\"\n",
        "  elif \"KDD\" in cell:\n",
        "    return \"kdd\"\n",
        "  elif \"TMLR\" in cell:\n",
        "    return \"tmlr\"\n",
        "  else:\n",
        "      return \"na\"\n",
        "\n",
        "data['Conference'] = data['Conference'].apply(clean_conference)\n",
        "data['Rationale'] = data['Rationale'].str.replace('** ', '', regex=False)\n",
        "\n",
        "data.loc[data['Conference'] == 'na', ['Publishable', 'Rationale']] = [0, 'na']\n",
        "\n",
        "further_updated_cleaned_file_path = 'updated_cleaned_final_results.csv'\n",
        "data.to_csv(further_updated_cleaned_file_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
